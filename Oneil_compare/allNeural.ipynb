{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221cb303-e1d3-4484-837d-7317ff93423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liupei/miniconda3/envs/pyg/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCTF_ConvKAN_18\n",
      "(351, 351)\n",
      "(325, 325)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(351, 351, 325)\n",
      "14679.0\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_0_times_0_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▉                                                                                                           | 50/500 [00:27<04:07,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.028767\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_0_times_1_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▋                                                                                                  | 87/500 [00:45<03:37,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.033940\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_0_times_2_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████▌                                                                                                         | 57/500 [00:30<03:55,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.029113\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_0_times_3_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▎                                                                                                     | 73/500 [00:38<03:43,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.033112\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_0_times_4_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▋                                                                                                      | 70/500 [00:36<03:45,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.022497\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.9985 0.9989 0.9924 0.9924 0.9941 0.9907 0.9908]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_1_times_0_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████                                                                                                    | 80/500 [00:46<04:03,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.026533\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_1_times_1_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▏                                                                                                  | 85/500 [00:49<04:02,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.035491\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_1_times_2_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████▎                                                                                               | 98/500 [00:57<03:56,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.026042\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_1_times_3_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▎                                                                                                     | 73/500 [00:42<04:08,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.023278\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_1_times_4_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████▎                                                                                                         | 56/500 [00:33<04:24,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.027207\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.9989 0.9992 0.9931 0.9931 0.9945 0.9916 0.9916]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_2_times_0_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▉                                                                                                       | 67/500 [00:39<04:14,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.022006\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_2_times_1_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████▊                                                                                                   | 83/500 [00:49<04:06,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.031103\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_2_times_2_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▋                                                                                                           | 49/500 [00:29<04:28,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.028341\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_2_times_3_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▏                                                                                                 | 89/500 [00:48<03:42,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.022144\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_2_times_4_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████▎                                                                                                         | 56/500 [00:29<03:53,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.028923\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.9989 0.9992 0.9933 0.9933 0.9958 0.9907 0.9908]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_3_times_0_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████                                                                                                     | 76/500 [00:39<03:41,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.027572\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_3_times_1_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▉                                                                                                           | 50/500 [00:26<03:56,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.033068\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_3_times_2_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▍                                                                                                  | 86/500 [00:44<03:35,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.030956\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_3_times_3_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████▎                                                                                                         | 56/500 [00:29<03:51,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.023697\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_3_times_4_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▉                                                                                                      | 71/500 [00:37<03:44,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.029593\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.999  0.9992 0.9919 0.9919 0.9953 0.9885 0.9886]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_4_times_0_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████                                                                                              | 102/500 [00:52<03:25,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.038227\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_4_times_1_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▎                                                                                                        | 60/500 [00:31<03:50,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.032888\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_4_times_2_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▏                                                                                                      | 68/500 [00:35<03:45,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.026525\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_4_times_3_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▊                                                                                                     | 75/500 [00:38<03:40,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.031369\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/1n/factors_4_times_4_fold.pkl\n",
      "torch.Size([351, 57]) torch.Size([351, 57]) torch.Size([325, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(351, 57)\n",
      "  (embeds2): Embedding(325, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▏                                                                                                       | 64/500 [00:33<03:48,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.025770\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.9985 0.9988 0.9922 0.9922 0.9933 0.9911 0.9911]]\n",
      "final:\t [[0.9988 0.9991 0.9926 0.9926 0.9946 0.9905 0.9906]]\n",
      "neg=1\n",
      "auc=0.9991\taupr=0.9988\tf1=0.9926\tacc=0.9926\trecall=0.9946\tspe=0.9905\tpre=0.9906\n",
      "\n",
      "16.0 16.173750638961792\n",
      "16.0 16.380422115325928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "from DataCombine_neg import GetData\n",
    "from ourMethod_gpu import Model\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_16, NCTF_ConvKAN_16_noeca1, NCTF_ConvKAN_16_noeca2, NCTF_ConvKAN_16_noeca12\n",
    "from newNCTF_NN_3 import NCTF_ConvMLP_16\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_13, NCTF_ConvKAN_1, ConvKAN\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_17, NCTF_ConvKAN_11, ConvKAN_1\n",
    "from newNCTF_NN_3 import Costco\n",
    "from newNCTF_NN_3 import CTF_DDI\n",
    "from newNCTF_NN_3 import DeepSynergy_new, DTF_new\n",
    "from newNCTF_NN_3 import NCTF_ConvMLP_16_noeca12\n",
    "from newNCTF_NN_3 import NCTF_ConvMLP_16_noeca2\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_CBAM\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_18,NCTF_ConvMLP_18,NCTF_KAN_18,NCTF_MLP_18\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_19\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_20\n",
    "from compareNumpyMethod import Model as numpyModel\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.backends import cudnn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "import math\n",
    "import time\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "# from utils import draw\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# def he_init_1(m):\n",
    "#     if isinstance(m, (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d)):\n",
    "#         torch.nn.init.kaiming_normal_(m.weight, mode = 'fan_in')\n",
    "\n",
    "def he_init_1(m):\n",
    "    if isinstance(m, (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d)):\n",
    "        #torch.nn.init.kaiming_normal_(m.weight, mode = 'fan_in')\n",
    "        torch.nn.init.kaiming_normal_(m.weight, a=0, mode = 'fan_in', nonlinearity='relu')\n",
    "        #torch.nn.init.kaiming_normal_(m.weight, a=0.01, mode = 'fan_in', nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "def train_test(model, criterion, lr, epochs, train_loader, val_loader, idxs_test, labels_test,k,k_folds,device):\n",
    "    print(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "    # 训练模型\n",
    "    # loss_train_list = []\n",
    "    # loss_test_list = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "    #for epoch in range(epochs):\n",
    "        ##训练\n",
    "        model.train()\n",
    "        train_loss, valid_loss = 0, 0\n",
    "        # loss_train_list_batch = []\n",
    "        for inputs in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "            outputs = model(inputs_gpu)\n",
    "            #print(inputs[-1].unsqueeze(1))\n",
    "            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(inputs)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        # loss_train_list.append(train_loss)\n",
    "\n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        for inputs in val_loader:\n",
    "            with torch.no_grad():\n",
    "                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                outputs = model(inputs_gpu)\n",
    "                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                val_loss += loss.item() * len(inputs)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        # loss_test_list.append(val_loss)\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "            break\n",
    "\n",
    "        if min_val > val_loss:\n",
    "            min_val = val_loss\n",
    "            min_epoch = epoch\n",
    "            # torch.save(Neural_Model, './best_model.pt')\n",
    "            testModel = model\n",
    "\n",
    "    # draw(loss_train_list, loss_test_list, str(k+1) + '-loss.png')\n",
    "    # print('Finished Training.\\nK-fold, Epoch, min val_loss ({},{},{})'.format(k, min_epoch, min_val))\n",
    "    # 测试模型\n",
    "    testModel.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs_gpu = idxs_test.T.to(device)\n",
    "        outputs = testModel(inputs_gpu)\n",
    "        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "    return outputs,testModel\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', msi=10, times=10,folds=5,a=0.5,negs=1,\n",
    "                 lr=0.001, epoch=150, batch_size=2048, nc=57,\n",
    "                 kernel_size=[(1, 3), (57, 1)], dims=[1],\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.numpyModel = numpyModel(model_name)\n",
    "        self.msi = msi\n",
    "        self.times = times\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.channel = nc\n",
    "        self.shape = drug_drug_data.X.shape\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dims = dims\n",
    "        self.folds = folds\n",
    "        self.a = a\n",
    "        self.negs = negs\n",
    "        self.parameters = kwargs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        k_folds = self.folds\n",
    "        fix_seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        kname = ['kernel1', 'kernel2','kernel3']\n",
    "        dname = ['dims1', 'dims2', 'dima3']\n",
    "        kernel_sizeList = [[(1, len(self.shape)), (r, 1)], [(r, 1), (1, len(self.shape))]]  # our\n",
    "        #kernel_sizeList = [[(1, len(self.shape)), (r, 1)], [(r, 1), (1, len(self.shape))], [(1, 1),(1, len(self.shape)), (r, 1)]]\n",
    "        dimsList = [[1], [self.channel, 1], [self.channel, self.channel, 1]]  # pre层\n",
    "        s1=kname[kernel_sizeList.index(self.kernel_size)]\n",
    "        s2=dname[dimsList.index(self.dims)]\n",
    "        df = pd.DataFrame(columns=['j', 'methods', 'times', 'folds', 'kernel', 'dims', 'aupr', 'auc', 'f1_score', 'accuracy',\n",
    "                     'recall', 'specificity',\n",
    "                     'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "\n",
    "            for k in range(k_folds):\n",
    "                ### Train data\n",
    "                # posIndex_train = torch.tensor(torch.nonzero(train_X == 1), dtype=torch.int)\n",
    "                posIndex_train = torch.tensor(index_matrix[:, np.where(poscv != k)[0]]).T\n",
    "                negIndex_train = torch.tensor(neg_matrix[:, np.where(negcv != k)[0]]).T\n",
    "                idxs_train = torch.cat((posIndex_train, negIndex_train), dim=0)\n",
    "                # print(idxs_train)\n",
    "                # print(idxs_train.shape)\n",
    "                poslabel_train = torch.ones(posIndex_train.shape[0])\n",
    "                neglabel_train = torch.zeros(negIndex_train.shape[0])\n",
    "                labels_train = torch.cat((poslabel_train, neglabel_train), dim=0)\n",
    "                # print(labels_train.shape)\n",
    "\n",
    "                ### 划分验证集\n",
    "                idxs = idxs_train.numpy().astype(int)\n",
    "                vals = labels_train.numpy().astype(float)\n",
    "                # print(idxs,vals)\n",
    "                # print(idxs.shape, vals.shape)\n",
    "                idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1)\n",
    "                # idxs_train, idxs_val, labels_train, labels_val = train_test_split(idxs_train, labels_train, test_size=0.1)\n",
    "\n",
    "                ### Test data\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = torch.cat((posIndex_test, negIndex_test), dim=0)\n",
    "                # print(idxs_test)\n",
    "                # print(idxs_test.shape)\n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                # print(labels_test.shape)\n",
    "\n",
    "                # 模型超参数\n",
    "                shape = self.drug_drug_data.X.shape\n",
    "                rank = self.parameters['r']\n",
    "                nc = self.channel\n",
    "                kernel_size = self.kernel_size  # 0-our 1-costco原始设置\n",
    "                # kernel_size2= [(rank,1),(1,len(shape))] #costco原始设置\n",
    "                dims = self.dims\n",
    "                lr = self.lr\n",
    "                epochs = self.epoch\n",
    "                batch_size = self.batch_size\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                # 创建数据加载器\n",
    "                idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                idxs_val = torch.LongTensor(idxs_val)\n",
    "                # idxs_test = torch.LongTensor(idxs_test)\n",
    "                labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                labels_val = torch.FloatTensor(labels_val)\n",
    "                # labels_test = torch.FloatTensor(labels_test)\n",
    "\n",
    "                train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                del train_dataset, val_dataset\n",
    "\n",
    "                msi = [1, 2,\n",
    "                       3,4,5,\n",
    "                       6,\n",
    "                       7,8,9,10,\n",
    "                       11,12,\n",
    "                          13,14,15,16,17,18]\n",
    "                mnameList = ['NCTF_ConvKAN_16','NCTF_ConvMLP_16',\n",
    "                             'NCTF_ConvKAN_16_noeca1','NCTF_ConvKAN_16_noeca2','NCTF_ConvKAN_16_noeca12',\n",
    "                             'NCTF_ConvKAN_17',\n",
    "                             'NCTF_ConvMLP_16_noeca12','NCTF_ConvKAN_13','NCTF_ConvKAN_1','ConvKAN',\n",
    "                             'NCTF_ConvMLP_16_noeca2','NCTF_ConvKAN_CBAM',\n",
    "                            'NCTF_ConvKAN_18','NCTF_ConvKAN_19','NCTF_ConvKAN_20','NCTF_ConvMLP_18','NCTF_KAN_18','NCTF_MLP_18']\n",
    "                mname = mnameList[msi.index(self.msi)]\n",
    "                print(mname)\n",
    "\n",
    "                ##### 获取NCTF学习所得的因子矩阵 M, C, D #####\n",
    "                ### end to end 学习M C D\n",
    "                # train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                # trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                # train_tensor[trainpos_index] = 0\n",
    "                # train_X = torch.tensor(train_tensor, dtype=torch.float32)\n",
    "                # S1 = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                # S2 = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                # _, M, C, D = self.model()(train_X, S1, S2,\n",
    "                #                           r=self.parameters['r'],\n",
    "                #                           mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                #                           alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                #                           lam=self.parameters['lam'],\n",
    "                #                           tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                #                           )\n",
    "                # print('NCTF')\n",
    "\n",
    "                ### 直接导入提前学习好的因子矩阵 \n",
    "                fname='NCTF_embeds/'+str(self.negs) +'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "                    M, C, D = pickle.load(f)\n",
    "                M = M.to(device)\n",
    "                C = C.to(device)\n",
    "                D = D.to(device)\n",
    "                \n",
    "                print(M.shape, C.shape, D.shape)\n",
    "                \n",
    "                ### 构建深度非线性模型 ### 定义损失函数 和 优化器\n",
    "                if self.msi == 1:\n",
    "                    Neural_Model = NCTF_ConvKAN_16(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 2:\n",
    "                    Neural_Model = NCTF_ConvMLP_16(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 3:\n",
    "                    Neural_Model = NCTF_ConvKAN_16_noeca1(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "                elif self.msi == 4:\n",
    "                    Neural_Model = NCTF_ConvKAN_16_noeca2(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "                elif self.msi == 5:\n",
    "                    Neural_Model = NCTF_ConvKAN_16_noeca12(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "                    \n",
    "                elif self.msi == 6:\n",
    "                    Neural_Model = NCTF_ConvKAN_17(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 7:\n",
    "                    Neural_Model = NCTF_ConvMLP_16_noeca12(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 8:\n",
    "                    Neural_Model = NCTF_ConvKAN_13(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 9:\n",
    "                    Neural_Model = NCTF_ConvKAN_1(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                  dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 10:\n",
    "                    Neural_Model = ConvKAN(shape, rank, nc, device,\n",
    "                                           kernel_size=kernel_size, dims=dims,\n",
    "                                           act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 11:\n",
    "                    Neural_Model = NCTF_ConvMLP_16_noeca2(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 12:\n",
    "                    Neural_Model = NCTF_ConvKAN_CBAM(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 13:\n",
    "                    Neural_Model = NCTF_ConvKAN_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                elif self.msi == 14:\n",
    "                    sim=[S1.to(device),S1.to(device),S2.to(device)]\n",
    "                    Neural_Model = NCTF_ConvKAN_19(shape, rank, M, C, D, device, sim, kernel_size,nc=[nc,nc],\n",
    "                                                  dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 15:\n",
    "                    sim=[S1.to(device),S1.to(device),S2.to(device)]\n",
    "                    Neural_Model = NCTF_ConvKAN_20(shape, rank, M, C, D, device, sim, kernel_size,nc=[nc,nc],\n",
    "                                                  dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 16:\n",
    "                    Neural_Model = NCTF_ConvMLP_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                elif self.msi == 17:\n",
    "                    Neural_Model = NCTF_KAN_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                elif self.msi == 18:\n",
    "                    Neural_Model = NCTF_MLP_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                # print(Neural_Model)\n",
    "                #criterion = nn.MSELoss()\n",
    "                Neural_Model.apply(he_init_1)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "                # optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "                outputs,testModel = train_test(Neural_Model, criterion, lr, epochs, train_loader, val_loader, idxs_test, labels_test, k, k_folds, device)\n",
    "\n",
    "                ### 存储每折每次的预测和真实值\n",
    "                # fname='newscore/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores_mse.pkl'\n",
    "                # print(fname)\n",
    "                # with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                #     pickle.dump([labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([testModel,idxs_test,labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                # print(idxs_test.T)\n",
    "                # print(idxs_test.T[0],len(idxs_test.T[0]))\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test.T[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test.T[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test.T[0],\n",
    "                    'm2': idxs_test.T[1],\n",
    "                    'd': idxs_test.T[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': outputs.T[0].cpu().numpy()  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "                \n",
    "                ### 计算评价指标\n",
    "                metrics = self.get_metrics_1(labels_test.cpu().numpy(), outputs.T[0].cpu().numpy())\n",
    "                # print(metrics)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, mname, i, k, kernel_size, dims, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j = j + 1\n",
    "\n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t', i + 1, ':\\t', result)\n",
    "            avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "\n",
    "        #print(self.a,str(self.a))\n",
    "        sname = s1 + '_' + s2 + '_' + str(self.a)\n",
    "        # fname = os.path.join('newablation/new3', mname + '_' + sname + '_hmddv32_5times5CV_1neg_results_bceheinit.csv')\n",
    "        # print(fname)\n",
    "        # df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        fname = os.path.join('compareTF', mname + '_' + sname + '_hmddv3.2_'+str(self.negs)+'neg_results_bceheinit_fixed_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        # print(j)\n",
    "        # print(df)\n",
    "        # print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t', results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t', results_2)\n",
    "        return results_1\n",
    "\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score = np.mat(real_score)\n",
    "        predict_score = np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        # sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "\n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "\n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "\n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "\n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "\n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "\n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "\n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "        \n",
    "    def get_metrics_2(self, real_score, predict_score):\n",
    "        np.random.seed(2024)\n",
    "        # trues, preds =  np.array(real_score).flatten(),np.array(predict_score).flatten()\n",
    "        print(predict_score)\n",
    "        trues, preds = real_score, expit(predict_score)\n",
    "        print(preds)\n",
    "        # print(preds, trues)\n",
    "        fpr1, tpr1, thresholds1 = roc_curve(trues, preds, pos_label=1)\n",
    "        auc_value = auc(fpr1, tpr1)\n",
    "        # print(thresholds1)\n",
    "        # auc_value = roc_auc_score(trues, preds)\n",
    "        precision, recall, thresholds2 = precision_recall_curve(trues, preds, pos_label=1)\n",
    "        precision = precision + np.finfo(float).tiny  # 添加极小值防止出现0\n",
    "        recall = recall + np.finfo(float).tiny  # 添加极小值防止出现0\n",
    "        # print(thresholds2)\n",
    "\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "        best_f1_index = f1_scores.argmax()\n",
    "        best_f1 = f1_scores[best_f1_index]\n",
    "        best_threshold = thresholds2[best_f1_index]\n",
    "        print('Best F1 Score:', best_f1)\n",
    "        print('Best Threshold:', best_threshold)\n",
    "        best_recall = recall[best_f1_index]\n",
    "        best_precision = precision[best_f1_index]\n",
    "        print(best_recall, best_precision)\n",
    "        f1_scores = 2 * (best_precision * best_recall) / (best_precision + best_recall)\n",
    "        print(f1_scores)\n",
    "        print(best_recall, best_precision, f1_scores)\n",
    "\n",
    "        # best_threshold = np.median(thresholds1) # 中位数\n",
    "\n",
    "        aupr = average_precision_score(trues, preds, pos_label=1)\n",
    "        preds1 = preds\n",
    "        preds1[preds > best_threshold] = 1\n",
    "        preds1[preds <= best_threshold] = 0\n",
    "\n",
    "        labels = [1]\n",
    "        TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        for label in labels:\n",
    "            preds_tmp = np.array([1 if pred == label else 0 for pred in preds1])\n",
    "            trues_tmp = np.array([1 if true == label else 0 for true in trues])\n",
    "            # print(preds_tmp, trues_tmp)\n",
    "            # print()\n",
    "            # TP预测为1真实为1\n",
    "            # TN预测为0真实为0\n",
    "            # FN预测为0真实为1\n",
    "            # FP预测为1真实为0\n",
    "            TP += ((preds_tmp == 1) & (trues_tmp == 1)).sum()\n",
    "            TN += ((preds_tmp == 0) & (trues_tmp == 0)).sum()\n",
    "            FN += ((preds_tmp == 0) & (trues_tmp == 1)).sum()\n",
    "            FP += ((preds_tmp == 1) & (trues_tmp == 0)).sum()\n",
    "        print(TP, FP, FN, TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        specificity = TN / (TN + FP)\n",
    "        npre = TN / (TN + FN)\n",
    "        fpr = FP / (TN + FP)\n",
    "        fnr = FN / (TP + FN)\n",
    "        print(recall, precision, f1_score)\n",
    "\n",
    "        return aupr, auc_value, f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "    def get_metrics_3(self, real_score, predict_score):\n",
    "        # fpr1, tpr1, thresholds = roc_curve(trues, preds, pos_label=1)\n",
    "        # auc_value = auc(fpr1, tpr1)\n",
    "        print(predict_score)\n",
    "        trues, preds = real_score, expit(predict_score)\n",
    "        print(preds)\n",
    "        auc_value = roc_auc_score(trues, preds)\n",
    "        # precision1, recall1, _ = precision_recall_curve(trues, preds, pos_label=1)\n",
    "        aupr = average_precision_score(trues, preds, pos_label=1)\n",
    "        preds1 = preds\n",
    "        # preds1[preds1 > 0.5] = 1\n",
    "        # preds1[preds1 <= 0.5] = 0\n",
    "        preds1[preds1 > np.median(preds)] = 1\n",
    "        preds1[preds1 <= np.median(preds)] = 0\n",
    "\n",
    "        labels = [1]\n",
    "        TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        for label in labels:\n",
    "            preds_tmp = np.array([1 if pred == label else 0 for pred in preds1])\n",
    "            trues_tmp = np.array([1 if true == label else 0 for true in trues])\n",
    "            print(preds_tmp, trues_tmp)\n",
    "            # print()\n",
    "            # TP预测为1真实为1\n",
    "            # TN预测为0真实为0\n",
    "            # FN预测为0真实为1\n",
    "            # FP预测为1真实为0\n",
    "            TP += ((preds_tmp == 1) & (trues_tmp == 1)).sum()\n",
    "            TN += ((preds_tmp == 0) & (trues_tmp == 0)).sum()\n",
    "            FN += ((preds_tmp == 0) & (trues_tmp == 1)).sum()\n",
    "            FP += ((preds_tmp == 1) & (trues_tmp == 0)).sum()\n",
    "        print(TP, FP, FN, TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        specificity = TN / (TN + FP)\n",
    "        npre = TN / (TN + FN)\n",
    "        fpr = FP / (TN + FP)\n",
    "        fnr = FN / (TP + FN)\n",
    "\n",
    "        return aupr, auc_value, f1, accuracy, recall, specificity, precision\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    ### 导入数据\n",
    "    since = time.time()\n",
    "    ###循环次数\n",
    "    times = 5\n",
    "    ### 导入数据\n",
    "    #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    # signal = 11\n",
    "    # miRNA_num = 351\n",
    "    # disease_num = 325\n",
    "    # neg = 1\n",
    "    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "    # #folder = '/mnt/sda/liupei/NCTF/newCode/data/ddi5cv'\n",
    "    # #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    # drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal,neg=neg)\n",
    "    ## 设置参数\n",
    "    lr = 0.0001  ## 设置均不同\n",
    "    batch_size = 256 #1024\n",
    "    epoch = 500\n",
    "    shape = 3\n",
    "    r = 57\n",
    "    nc = int(2*r)\n",
    "    kernel_sizeList = [[(1, shape), (r, 1)], [(r, 1), (1, shape)]]  # our\n",
    "    dimsList = [[1], [nc, 1], [nc, nc, 1]]  # pre层\n",
    "    ### 搜索最优配置\n",
    "    # msiList = [1, 2, 310, 311, 312, 313, 314,315,316,320, 321, 322, 323,324,325,326,327]\n",
    "    # mnameList = ['ConvMLP', 'ConvKAN',\n",
    "    #              'NCTF_ConvMLP', 'NCTF_ConvMLP_1', 'NCTF_ConvMLP_12', 'NCTF_ConvMLP_13','NCTF_ConvMLP_14', 'NCTF_ConvMLP_15','NCTF_ConvMLP_16',\n",
    "    #              'NCTF_ConvKAN', 'NCTF_ConvKAN_1', 'NCTF_ConvKAN_12', 'NCTF_ConvKAN_13', 'NCTF_ConvKAN_14', 'NCTF_ConvKAN_15',\n",
    "    #              'NCTF_ConvKAN_16', 'NCTF_ConvKAN_17']\n",
    "    # msiList = [1, 2,\n",
    "    #            3,4,5,\n",
    "    #            6]\n",
    "    # mnameList = ['NCTF_ConvKAN_16','NCTF_ConvMLP_16',\n",
    "    #              'NCTF_ConvKAN_16_noeca1','NCTF_ConvKAN_16_noeca2','NCTF_ConvKAN_16_noeca12',\n",
    "    #              'NCTF_ConvKAN_17']\n",
    "    msiList = [1, 2,\n",
    "               3,4,5,\n",
    "               6,\n",
    "               7,8,9,10,\n",
    "               11,\n",
    "              12,13,14,15,16,17,18]\n",
    "    mnameList = ['NCTF_ConvKAN_16','NCTF_ConvMLP_16',\n",
    "                 'NCTF_ConvKAN_16_noeca1','NCTF_ConvKAN_16_noeca2','NCTF_ConvKAN_16_noeca12',\n",
    "                 'NCTF_ConvKAN_17',\n",
    "                 'NCTF_ConvMLP_16_noeca12','NCTF_ConvKAN_13','NCTF_ConvKAN_1','ConvKAN',\n",
    "                 'NCTF_ConvMLP_16_noeca2',\n",
    "                'NCTF_ConvKAN_CBAM','NCTF_ConvKAN_18','NCTF_ConvKAN_19','NCTF_ConvKAN_20','NCTF_ConvMLP_18','NCTF_KAN_18','NCTF_MLP_18']\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    i = 0\n",
    "    kernel_size = kernel_sizeList[0]\n",
    "    #dims = dimsList[0]\n",
    "    folds = 5\n",
    "    mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001\n",
    "    #mu,eta,alpha,beta,lam=0.25,2,0.125,0.125,0.001\n",
    "    a=0.5\n",
    "    signal = 11\n",
    "    for msi in [13]:\n",
    "        mname = mnameList[msiList.index(msi)]\n",
    "        print(mname)\n",
    "        # if msi in [2,7,11,16]:\n",
    "        #     dims=dimsList[1]\n",
    "        # else:\n",
    "        #     dims=dimsList[0]\n",
    "        dims = dimsList[0]# one-layer\n",
    "        #for neg in [1,2,4,6,8,10]:\n",
    "        for neg in [1]:\n",
    "            folder = '/mnt/sda/liupei/NCTF_new/data/hmddv32_neg/'+str(neg)+'n'\n",
    "            drug_drug_data = GetData(miRNA_num=351, disease_num=325,filefolder=folder,signal=signal,neg=neg)\n",
    "            since1 = time.time()\n",
    "            experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32', msi=msi, times=times, folds=folds,a=a,negs=neg,\n",
    "                                     lr=lr, epoch=epoch, batch_size=batch_size, nc=nc,\n",
    "                                     kernel_size=kernel_size, dims=dims,\n",
    "                                     r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol = 1e-4, max_iter = 100)\n",
    "    \n",
    "            aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "            df.loc[i] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity,precision]\n",
    "            print(f\"neg={neg}\")\n",
    "            print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "            i = i + 1\n",
    "            time_elapsed1 = time.time() - since1\n",
    "            print(time_elapsed1 // 60, time_elapsed1 % 60)\n",
    "\n",
    "    df.to_csv('NCTFConvKAN18_negResults_fixed_new.csv',index=False)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54052cc9-c282-4839-801a-f3f3666f6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTF_DDI 90\n",
      "1\n",
      "(351, 351)\n",
      "(325, 325)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(351, 351, 325)\n",
      "14679.0\n",
      "(351, 351)\n",
      "(351, 351)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(351, 351, 325)\n",
      "14679.0\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:01<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.190844\n",
      "tensor([[ 2.8342],\n",
      "        [ 6.2300],\n",
      "        [ 1.1550],\n",
      "        ...,\n",
      "        [-3.8365],\n",
      "        [-1.5678],\n",
      "        [-7.0677]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_0_times_0_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.152867\n",
      "tensor([[-0.6544],\n",
      "        [ 4.0768],\n",
      "        [ 0.8425],\n",
      "        ...,\n",
      "        [ 0.0901],\n",
      "        [-4.3025],\n",
      "        [-7.8134]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_0_times_1_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:58<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.135864\n",
      "tensor([[ 7.0026],\n",
      "        [ 6.9328],\n",
      "        [ 3.3446],\n",
      "        ...,\n",
      "        [-9.4370],\n",
      "        [-4.2763],\n",
      "        [-8.2298]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_0_times_2_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 297/300 [01:00<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.159464\n",
      "tensor([[-3.1880],\n",
      "        [ 5.0606],\n",
      "        [ 6.7853],\n",
      "        ...,\n",
      "        [-5.9359],\n",
      "        [-4.3292],\n",
      "        [-5.7210]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_0_times_3_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:01<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.189136\n",
      "tensor([[-2.7055],\n",
      "        [-0.3634],\n",
      "        [-0.5339],\n",
      "        ...,\n",
      "        [-4.1487],\n",
      "        [-6.7264],\n",
      "        [-5.0427]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.9837 0.9836 0.9347 0.9337 0.9482 0.9191 0.9217]]\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 296/300 [00:57<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.206132\n",
      "tensor([[ 1.1682],\n",
      "        [ 5.0056],\n",
      "        [ 0.9584],\n",
      "        ...,\n",
      "        [-2.3264],\n",
      "        [-6.8506],\n",
      "        [-7.1086]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_1_times_0_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:56<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.155830\n",
      "tensor([[ 6.6606],\n",
      "        [ 6.0199],\n",
      "        [ 0.8132],\n",
      "        ...,\n",
      "        [-3.4279],\n",
      "        [-7.0832],\n",
      "        [-8.2061]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_1_times_1_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████████████████████▋                                       | 200/300 [00:37<00:18,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.214994\n",
      "tensor([[-3.0671],\n",
      "        [ 3.0003],\n",
      "        [ 0.7384],\n",
      "        ...,\n",
      "        [-1.1986],\n",
      "        [-2.0594],\n",
      "        [-2.9903]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_1_times_2_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 263/300 [00:50<00:07,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.175693\n",
      "tensor([[-0.0434],\n",
      "        [ 0.1063],\n",
      "        [ 4.8485],\n",
      "        ...,\n",
      "        [-7.0034],\n",
      "        [-5.0295],\n",
      "        [-7.2016]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_1_times_3_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:00<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.148904\n",
      "tensor([[ 0.5439],\n",
      "        [ 5.7826],\n",
      "        [ 1.2326],\n",
      "        ...,\n",
      "        [-0.9905],\n",
      "        [-7.1221],\n",
      "        [-8.6194]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.9816 0.981  0.9308 0.9304 0.9357 0.9252 0.9261]]\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:01<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.183911\n",
      "tensor([[ 5.1460],\n",
      "        [ 1.5951],\n",
      "        [ 2.1601],\n",
      "        ...,\n",
      "        [ 1.7034],\n",
      "        [-3.4635],\n",
      "        [-4.6678]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_2_times_0_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:59<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.160168\n",
      "tensor([[ 2.0256],\n",
      "        [ 8.0718],\n",
      "        [ 4.7112],\n",
      "        ...,\n",
      "        [-3.1656],\n",
      "        [-1.2461],\n",
      "        [-4.4958]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_2_times_1_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████████████████████████████████████████████████████████████▉                                 | 216/300 [00:43<00:16,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.232273\n",
      "tensor([[-3.1315],\n",
      "        [ 1.7372],\n",
      "        [ 2.9319],\n",
      "        ...,\n",
      "        [ 5.8667],\n",
      "        [-4.1038],\n",
      "        [ 2.3196]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_2_times_2_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:00<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.143380\n",
      "tensor([[ 5.4208],\n",
      "        [ 2.1776],\n",
      "        [ 1.6370],\n",
      "        ...,\n",
      "        [ 0.3921],\n",
      "        [-6.8621],\n",
      "        [-1.5026]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_2_times_3_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:59<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.183012\n",
      "tensor([[-1.3879],\n",
      "        [-2.1868],\n",
      "        [ 5.8722],\n",
      "        ...,\n",
      "        [ 0.1063],\n",
      "        [-0.0930],\n",
      "        [-3.9379]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.9818 0.9807 0.9289 0.9293 0.924  0.9346 0.9339]]\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:56<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.163292\n",
      "tensor([[-3.5664],\n",
      "        [ 4.0259],\n",
      "        [ 1.1812],\n",
      "        ...,\n",
      "        [-6.0027],\n",
      "        [-7.0355],\n",
      "        [-4.2444]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_3_times_0_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 280/300 [00:52<00:03,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.200113\n",
      "tensor([[ 6.4513],\n",
      "        [ 5.8913],\n",
      "        [ 3.5443],\n",
      "        ...,\n",
      "        [-0.5530],\n",
      "        [-7.8781],\n",
      "        [-7.8947]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_3_times_1_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:55<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.176503\n",
      "tensor([[-4.0000],\n",
      "        [-2.1105],\n",
      "        [ 1.1383],\n",
      "        ...,\n",
      "        [-1.4353],\n",
      "        [-1.4916],\n",
      "        [-3.0201]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_3_times_2_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████████████████████▎                                         | 194/300 [00:35<00:19,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.219471\n",
      "tensor([[ 5.8481],\n",
      "        [ 3.3386],\n",
      "        [ 0.6744],\n",
      "        ...,\n",
      "        [-2.6694],\n",
      "        [-2.8663],\n",
      "        [ 3.3894]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_3_times_3_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████████████████▌                                   | 210/300 [00:39<00:16,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.174276\n",
      "tensor([[ 5.0897],\n",
      "        [ 3.8448],\n",
      "        [ 3.4147],\n",
      "        ...,\n",
      "        [-6.5079],\n",
      "        [-5.5156],\n",
      "        [-5.0953]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.9799 0.979  0.9245 0.9245 0.9246 0.9243 0.9244]]\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:55<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.150255\n",
      "tensor([[ 3.8417],\n",
      "        [ 3.8120],\n",
      "        [ 3.7824],\n",
      "        ...,\n",
      "        [-2.2877],\n",
      "        [-4.6516],\n",
      "        [-7.0833]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_4_times_0_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:54<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.207449\n",
      "tensor([[ 1.4573],\n",
      "        [-1.9271],\n",
      "        [ 5.1384],\n",
      "        ...,\n",
      "        [-3.2932],\n",
      "        [-5.9805],\n",
      "        [-3.8493]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_4_times_1_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:53<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.132106\n",
      "tensor([[-1.0292],\n",
      "        [ 4.4651],\n",
      "        [ 4.2320],\n",
      "        ...,\n",
      "        [-3.6447],\n",
      "        [-8.7672],\n",
      "        [-2.7568]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_4_times_2_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████▋                            | 228/300 [00:41<00:13,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.211967\n",
      "tensor([[ 3.0729],\n",
      "        [ 3.8463],\n",
      "        [ 0.6489],\n",
      "        ...,\n",
      "        [-5.6293],\n",
      "        [-5.2064],\n",
      "        [-4.1491]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_4_times_3_foldscores.pkl\n",
      "CTF_DDI\n",
      "CTF_DDI(\n",
      "  (Modelist): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:53<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.155012\n",
      "tensor([[-1.6768],\n",
      "        [ 4.9286],\n",
      "        [ 3.4420],\n",
      "        ...,\n",
      "        [-0.4549],\n",
      "        [-3.0631],\n",
      "        [-2.5188]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/CTF_DDI_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.9828 0.9824 0.9335 0.9333 0.9377 0.9288 0.9294]]\n",
      "final:\t [[0.982  0.9813 0.9305 0.9302 0.934  0.9264 0.9271]]\n",
      "i=0\ttimes=5\tmethods=CTF_DDI\tmsi=90\tneg=1\n",
      "auc=0.9813\taupr=0.982\tf1=0.9305\tacc=0.9302\trecall=0.934\tspe=0.9264\tpre=0.9271\n",
      "\n",
      "22.0 29.701514720916748\n",
      "22.0 29.915620803833008\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "from DataCombine_neg import GetData\n",
    "from ourMethod_gpu import Model\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_16, NCTF_ConvKAN_16_noeca1, NCTF_ConvKAN_16_noeca2, NCTF_ConvKAN_16_noeca12\n",
    "from newNCTF_NN_2 import NCTF_ConvMLP_16\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_13, NCTF_ConvKAN_1, ConvKAN\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_17, NCTF_ConvKAN_11, ConvKAN_1\n",
    "from newNCTF_NN_2 import Costco\n",
    "from newNCTF_NN_2 import CTF_DDI\n",
    "from newNCTF_NN_2 import DeepSynergy_new, DTF_new\n",
    "from compareNumpyMethod import Model as numpyModel\n",
    "#from DataCombine_drug import GetData\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.backends import cudnn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "import math\n",
    "import time\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "\n",
    "# from utils import draw\n",
    "\n",
    "# tl.set_backend('pytorch')\n",
    "\n",
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "def normalize_Deepsynergy(X, means1=None, std1=None, means2=None, std2=None, feat_filt=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    if feat_filt is None:\n",
    "        feat_filt = std1!=0\n",
    "    X = X[:,feat_filt]\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1[feat_filt]\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1, feat_filt)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1, feat_filt)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        X[:,std2==0]=0\n",
    "        return(X, means1, std1, means2, std2, feat_filt)      \n",
    "\n",
    "def normalize_DTF(X, means1=None, std1=None, means2=None, std2=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if norm is None:\n",
    "        return (X, means1, std1, feat_filt)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        return(X, means1, std1, means2, std2)\n",
    "        \n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', msi=10, times=10, negs=1,\n",
    "                 lr=0.001, epoch=150, batch_size=2048, nc=57,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.numpyModel = numpyModel(model_name)\n",
    "        self.msi = msi\n",
    "        self.times = times\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.channel = nc\n",
    "        self.negs = negs\n",
    "        self.parameters = kwargs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = 5\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'methods', 'times', 'folds', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity','precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "\n",
    "            for k in range(k_folds):\n",
    "                ### Train data\n",
    "                # posIndex_train = torch.tensor(torch.nonzero(train_X == 1), dtype=torch.int)\n",
    "                posIndex_train = torch.tensor(index_matrix[:, np.where(poscv != k)[0]]).T\n",
    "                negIndex_train = torch.tensor(neg_matrix[:, np.where(negcv != k)[0]]).T\n",
    "                idxs_train = torch.cat((posIndex_train, negIndex_train), dim=0)\n",
    "                # print(idxs_train)\n",
    "                # print(idxs_train.shape)\n",
    "                poslabel_train = torch.ones(posIndex_train.shape[0])\n",
    "                neglabel_train = torch.zeros(negIndex_train.shape[0])\n",
    "                labels_train = torch.cat((poslabel_train, neglabel_train), dim=0)\n",
    "                # print(labels_train.shape)\n",
    "\n",
    "                ### 划分验证集\n",
    "                idxs = idxs_train.numpy().astype(int)\n",
    "                vals = labels_train.numpy().astype(float)\n",
    "                # print(idxs,vals)\n",
    "                # print(idxs.shape, vals.shape)\n",
    "                idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                # idxs_train, idxs_val, labels_train, labels_val = train_test_split(idxs_train, labels_train, test_size=0.1)\n",
    "\n",
    "                ### Test data\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = torch.cat((posIndex_test, negIndex_test), dim=0)\n",
    "                # print(idxs_test)\n",
    "                # print(idxs_test.shape)\n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                # print(labels_test.shape)\n",
    "\n",
    "                # 模型超参数\n",
    "                shape = self.drug_drug_data.X.shape\n",
    "                rank = self.parameters['r']\n",
    "                nc = self.channel\n",
    "                lr = self.lr\n",
    "                epochs = self.epoch\n",
    "                batch_size = self.batch_size\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                methodList = [20, 70, 80, 90]\n",
    "                mnameList = ['Costco', 'DeepSynergy', 'DTF', 'CTF_DDI']\n",
    "\n",
    "                ### 构建深度非线性模型 ### 定义损失函数 和 优化器\n",
    "                if self.msi == 20:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    Neural_Model = Costco(shape, rank, nc, device).to(device)  # Costco\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 70:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    ### 获得三个维度的相似度特征\n",
    "                    M = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    C = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    D = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "                    # M, C, D = getSimFeature(folder=folder, signal=11)\n",
    "                    # M = torch.FloatTensor(M)\n",
    "                    # C = torch.FloatTensor(C)\n",
    "                    # D = torch.FloatTensor(D)\n",
    "                    # inputSize= (M.shape[1]+C.shape[1]+D.shape[1])\n",
    "                    # print(inputSize)\n",
    "                    \n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "                    norm = 'tanh'    \n",
    "                    ## training \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_val, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_tr, mean, std, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, feat_filt = normalize_Deepsynergy(X_val, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "\n",
    "                    #print(X_tr.shape,X_val.shape)\n",
    "                    ## testing    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_train, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_test, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_train, mean, std, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, feat_filt = normalize_Deepsynergy(X_test, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                 \n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DeepSynergy_new(shape, rank, inputSize, \n",
    "                                               X_tr,X_val,X_train,X_test,\n",
    "                                               act_func=nn.ReLU(),dropout=0.5, input_dropout=0.2,\n",
    "                                               dims=[8182, 4096, 1]).to(device)\n",
    "                    # [8182, 4096, 1];[4096, 2048, 1]\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    # optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "                    optimizer = optim.SGD(Neural_Model.parameters(), lr=lr, momentum=0.5)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                        # label_pre=outputs\n",
    "                        # label_pre[ label_pre < threshold ] = 0\n",
    "                        # label_pre[ label_pre >= threshold ] = 1\n",
    "                        # outputs[ outputs < 30 ] = 0\n",
    "                        # outputs[ outputs >= 30 ] = 1\n",
    "                        # labels_test [labels_test<30] = 0\n",
    "                        # labels_test [labels_test >=30] =1\n",
    "                        #print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 80:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embM_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    M = emb.values\n",
    "                    #M = torch.FloatTensor(M).to(device)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embC_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    C = emb.values\n",
    "                    #C = torch.FloatTensor(C).to(device)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embD_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    D = emb.values\n",
    "                    #D = torch.FloatTensor(D).to(device)\n",
    "                    print(M.shape,C.shape,D.shape)\n",
    "\n",
    "                    M = torch.FloatTensor(M)\n",
    "                    C = torch.FloatTensor(C)\n",
    "                    D = torch.FloatTensor(D)\n",
    "                    ### 得到数据集的特征\n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    ### 数据特征标准化\n",
    "                    norm = 'tanh'    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2 = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2 = normalize_DTF(X_val, mean, std, mean2, std2,  norm=norm)\n",
    "                        X_test, mean, std, mean2, std2 = normalize_DTF(X_test, mean, std, mean2, std2, norm=norm)    \n",
    "                    else:\n",
    "                        X_tr, mean, std = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std = normalize_DTF(X_val, mean, std, norm=norm)\n",
    "                        X_test, mean, std = normalize_DTF(X_test, mean, std, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    print(labels_train1,labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    ## 3000\n",
    "                    #inputSize = rank * len(shape)\n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DTF_new(shape, rank, inputSize, embeds=[M, C, D], nn_struc=[2048, 1024, 512],\n",
    "                                       input_dp=0.2, first_dp=0.5, second_dp=0.5).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    criterion = nn.BCELoss()  # binary crossentropy loss\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                    \n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            #print(inputs[-1])\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    #labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                \n",
    "                elif self.msi == 90:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "\n",
    "                    # tl.set_backend('numpy')\n",
    "                    # train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                    # trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                    # train_tensor[trainpos_index] = 0\n",
    "                    # S1 = np.mat(self.drug_drug_data.S1)\n",
    "                    # S2 = np.mat(self.drug_drug_data.S2)\n",
    "                    # _, M, C, D = self.numpyModel()(train_tensor, S1, S2,\n",
    "                    #                                r=self.parameters['r'],\n",
    "                    #                                mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                    #                                alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                    #                                lam=self.parameters['lam'],\n",
    "                    #                                tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                    #                                )\n",
    "                    # print('CTF')\n",
    "                    # # print(M.shape, C.shape, D.shape)\n",
    "                    # M = torch.FloatTensor(M).to(device)\n",
    "                    # C = torch.FloatTensor(C).to(device)\n",
    "                    # D = torch.FloatTensor(D).to(device)\n",
    "                    # print(M.shape, C.shape, D.shape)\n",
    "                    # print(M)\n",
    "\n",
    "                    ### 直接导入提前学习好的因子矩阵 \n",
    "                    fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    #fname='/mnt/sda/liupei/NCTF/newCode/hmddv32/compare/neg/CTF_embeds/1n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "                        M, C, D = pickle.load(f)\n",
    "                    \n",
    "                    M = torch.FloatTensor(M).to(device)\n",
    "                    C = torch.FloatTensor(C).to(device)\n",
    "                    D = torch.FloatTensor(D).to(device)\n",
    "                    \n",
    "                    Neural_Model = CTF_DDI(shape, rank, hids_size=[256, 256, 128], embeds=[M, C, D], device=device).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([testModel,idxs_test,labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                # print(idxs_test.T)\n",
    "                # print(idxs_test.T[0],len(idxs_test.T[0]))\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test.T[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test.T[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test.T[0],\n",
    "                    'm2': idxs_test.T[1],\n",
    "                    'd': idxs_test.T[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': outputs.T[0].cpu().numpy()  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "                \n",
    "                metrics = self.get_metrics_1(labels_test.cpu().numpy(), outputs.T[0].cpu().numpy())\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, mname, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j = j + 1\n",
    "\n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t', i + 1, ':\\t', result)\n",
    "            avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "\n",
    "        fname = os.path.join('compareTF', mname + '_hmddv3.2_'+str(self.negs)+'neg_results_0.5lam_fixed.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        #print(j)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t', results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t', results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score = np.mat(real_score)\n",
    "        predict_score = np.mat(predict_score)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "\n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "\n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "\n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "\n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "\n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "\n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    ### 导入数据\n",
    "    since = time.time()\n",
    "    #df = pd.DataFrame(columns=['methods', 'times', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    methodList = [20, 70, 80, 90]\n",
    "    mnameList = ['Costco', 'DeepSynergy','DTF', 'CTF_DDI']\n",
    "    ## 设置参数\n",
    "    lr = 0.0001  ## 设置均不同\n",
    "    batch_size = 1024\n",
    "    epoch = 500\n",
    "    shape = 3\n",
    "    r = 57\n",
    "    nc = int(2*r)\n",
    "    times = 5\n",
    "    folds = 5\n",
    "    #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    #signal = 11\n",
    "    miRNA_num=351\n",
    "    disease_num=325\n",
    "    #drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "    mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    i = 0\n",
    "    for msi in [90]:\n",
    "        mname = mnameList[methodList.index(msi)]\n",
    "        print(mname, msi)\n",
    "        #for neg in [1,2,4,6,8,10]:\n",
    "        for neg in [1]:\n",
    "            folder = '/mnt/sda/liupei/NCTF_new/data/hmddv32_neg/'+str(neg)+'n'\n",
    "            signal = 11\n",
    "            print(neg)\n",
    "            drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num,filefolder=folder,signal=signal,neg=neg)\n",
    "            since1 = time.time()\n",
    "            if msi == 20:\n",
    "                ## Costco\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',msi=msi, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=500, batch_size=256, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 70:\n",
    "                ### DeepSynergy DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=70, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=64, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "    \n",
    "            elif msi == 80:\n",
    "                ## DTF batch_size=128 r=1000\n",
    "                ### DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=80, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=128, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 90:\n",
    "                ## CTF_DDI batch_size=1000 epoch=300 r=51 max_iter=200\n",
    "                signal = 21  # 22\n",
    "                drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal,neg=neg)\n",
    "                # DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='CTF',\n",
    "                                         msi=90, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=300, batch_size=1000, nc=nc,\n",
    "                                         r=r, mu=0.5, eta=0.2, alpha=0.5, beta=0.5,lam=0.5, tol=1e-6, max_iter=100)\n",
    "\n",
    "            aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "            df.loc[i] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "            # experiment.CV_triplet()[0]\n",
    "            print(f\"i={i}\\ttimes={times}\\tmethods={mname}\\tmsi={msi}\\tneg={neg}\")\n",
    "            print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "            i = i + 1\n",
    "            time_elapsed1 = time.time() - since1\n",
    "            print(time_elapsed1 // 60, time_elapsed1 % 60)\n",
    "            \n",
    "    df.to_csv('CTFDDI_negResults_0.5lam_fixed.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ae946d-7d31-447b-8a23-6d89022d3ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costco 20\n",
      "1\n",
      "(351, 351)\n",
      "(325, 325)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(351, 351, 325)\n",
      "14679.0\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████▎                                                                                                   | 81/500 [00:27<02:20,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.070948\n",
      "tensor([[0.8420],\n",
      "        [0.7804],\n",
      "        [0.6991],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_0_times_0_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████▌                                                                                          | 117/500 [00:37<02:01,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.065844\n",
      "tensor([[0.0000],\n",
      "        [0.2586],\n",
      "        [0.8195],\n",
      "        ...,\n",
      "        [0.3849],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_0_times_1_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▏                                                                                                  | 85/500 [00:28<02:16,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.061123\n",
      "tensor([[0.9589],\n",
      "        [0.9586],\n",
      "        [0.8013],\n",
      "        ...,\n",
      "        [0.4117],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_0_times_2_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████                                                                                                    | 80/500 [00:25<02:12,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.061946\n",
      "tensor([[0.9487],\n",
      "        [0.9169],\n",
      "        [0.9761],\n",
      "        ...,\n",
      "        [0.2104],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_0_times_3_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████                                                                                              | 102/500 [00:32<02:08,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.071101\n",
      "tensor([[1.0030],\n",
      "        [1.0084],\n",
      "        [0.0123],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.9553 0.9646 0.9182 0.917  0.9321 0.9018 0.9048]]\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████                                                                                                | 97/500 [00:30<02:07,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.066946\n",
      "tensor([[0.9297],\n",
      "        [0.9495],\n",
      "        [0.8942],\n",
      "        ...,\n",
      "        [0.1222],\n",
      "        [0.0000],\n",
      "        [0.2873]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_1_times_0_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████▌                                                                                                   | 82/500 [00:23<02:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.067402\n",
      "tensor([[0.1298],\n",
      "        [0.3157],\n",
      "        [0.4435],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.7395]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_1_times_1_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▊                                                                                                | 96/500 [00:31<02:14,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.063298\n",
      "tensor([[0.9714],\n",
      "        [0.9502],\n",
      "        [1.0342],\n",
      "        ...,\n",
      "        [0.7681],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_1_times_2_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▋                                                                                                 | 91/500 [00:30<02:17,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.065472\n",
      "tensor([[0.9621],\n",
      "        [1.0777],\n",
      "        [0.8332],\n",
      "        ...,\n",
      "        [0.7932],\n",
      "        [0.0607],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_1_times_3_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▉                                                                                                  | 88/500 [00:26<02:06,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.066777\n",
      "tensor([[0.1731],\n",
      "        [0.6136],\n",
      "        [1.0606],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.953  0.9637 0.9192 0.9179 0.9335 0.9024 0.9057]]\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▍                                                                                                                    | 10/500 [00:03<02:35,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.500000\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_2_times_0_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████▌                                                                                             | 104/500 [00:34<02:10,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.064268\n",
      "tensor([[0.9336],\n",
      "        [0.9597],\n",
      "        [0.8774],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.9319],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_2_times_1_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▎                                                                                                     | 73/500 [00:24<02:25,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.072826\n",
      "tensor([[0.8081],\n",
      "        [0.1326],\n",
      "        [0.5007],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_2_times_2_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████▍                                                                                           | 112/500 [00:35<02:04,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.068120\n",
      "tensor([[0.9389],\n",
      "        [0.8069],\n",
      "        [0.8734],\n",
      "        ...,\n",
      "        [0.6735],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_2_times_3_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▋                                                                                    | 143/500 [00:46<01:55,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.067868\n",
      "tensor([[0.9691],\n",
      "        [0.3480],\n",
      "        [0.9352],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.1130],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.9111 0.8702 0.8644 0.8305 0.9371 0.724  0.8253]]\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▍                                                                                                 | 90/500 [00:27<02:05,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.066367\n",
      "tensor([[0.4852],\n",
      "        [0.0033],\n",
      "        [0.8741],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.9205],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_3_times_0_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▋                                                                                                      | 70/500 [00:21<02:13,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.070456\n",
      "tensor([[1.0294],\n",
      "        [0.9629],\n",
      "        [0.8835],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0923],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_3_times_1_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▏                                                                                                  | 85/500 [00:28<02:20,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.064397\n",
      "tensor([[0.4212],\n",
      "        [0.0392],\n",
      "        [0.9537],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.4634],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_3_times_2_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▏                                                                                                | 93/500 [00:30<02:12,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.065743\n",
      "tensor([[0.9576],\n",
      "        [1.0520],\n",
      "        [0.8752],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.2712],\n",
      "        [0.8385]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_3_times_3_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▍                                                                                                 | 90/500 [00:29<02:12,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.065722\n",
      "tensor([[0.4425],\n",
      "        [0.7362],\n",
      "        [0.9765],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.9549 0.964  0.9166 0.9157 0.9264 0.9049 0.9069]]\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▏                                                                                                  | 85/500 [00:28<02:20,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.064460\n",
      "tensor([[0.4798],\n",
      "        [0.8795],\n",
      "        [0.9158],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.6019],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_4_times_0_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▉                                                                                                 | 92/500 [00:28<02:05,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.063114\n",
      "tensor([[0.8086],\n",
      "        [0.4814],\n",
      "        [0.9859],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_4_times_1_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▊                                                                                                    | 79/500 [00:22<02:01,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.067112\n",
      "tensor([[0.8788],\n",
      "        [0.9161],\n",
      "        [0.0141],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_4_times_2_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████▎                                                                                             | 103/500 [00:32<02:07,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.063449\n",
      "tensor([[0.9658],\n",
      "        [0.8647],\n",
      "        [0.9949],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3722]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_4_times_3_foldscores.pkl\n",
      "Costco\n",
      "Costco(\n",
      "  (embeds): ModuleList(\n",
      "    (0-1): 2 x Embedding(351, 57)\n",
      "    (2): Embedding(325, 57)\n",
      "  )\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=114, out_features=114, bias=True)\n",
      "  (fc2): Linear(in_features=114, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████▌                                                                                          | 117/500 [00:38<02:06,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.064912\n",
      "tensor([[0.8991],\n",
      "        [0.8527],\n",
      "        [1.0243],\n",
      "        ...,\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/Costco_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.9569 0.9656 0.92   0.9195 0.9262 0.9129 0.9142]]\n",
      "final:\t [[0.9463 0.9456 0.9077 0.9001 0.9311 0.8692 0.8914]]\n",
      "i=0\ttimes=5\tmethods=Costco\tmsi=20\tneg=1\n",
      "auc=0.9456\taupr=0.9463\tf1=0.9077\tacc=0.9001\trecall=0.9311\tspe=0.8692\tpre=0.8914\n",
      "\n",
      "12.0 10.528818845748901\n",
      "12.0 10.723098278045654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "from DataCombine_neg import GetData\n",
    "from ourMethod_gpu import Model\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_16, NCTF_ConvKAN_16_noeca1, NCTF_ConvKAN_16_noeca2, NCTF_ConvKAN_16_noeca12\n",
    "from newNCTF_NN_2 import NCTF_ConvMLP_16\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_13, NCTF_ConvKAN_1, ConvKAN\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_17, NCTF_ConvKAN_11, ConvKAN_1\n",
    "from newNCTF_NN_2 import Costco\n",
    "from newNCTF_NN_2 import CTF_DDI\n",
    "from newNCTF_NN_2 import DeepSynergy_new, DTF_new\n",
    "from compareNumpyMethod import Model as numpyModel\n",
    "#from DataCombine_drug import GetData\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.backends import cudnn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "import math\n",
    "import time\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "\n",
    "# from utils import draw\n",
    "\n",
    "# tl.set_backend('pytorch')\n",
    "\n",
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "def normalize_Deepsynergy(X, means1=None, std1=None, means2=None, std2=None, feat_filt=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    if feat_filt is None:\n",
    "        feat_filt = std1!=0\n",
    "    X = X[:,feat_filt]\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1[feat_filt]\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1, feat_filt)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1, feat_filt)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        X[:,std2==0]=0\n",
    "        return(X, means1, std1, means2, std2, feat_filt)      \n",
    "\n",
    "def normalize_DTF(X, means1=None, std1=None, means2=None, std2=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if norm is None:\n",
    "        return (X, means1, std1, feat_filt)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        return(X, means1, std1, means2, std2)\n",
    "        \n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', msi=10, times=10, negs=1,\n",
    "                 lr=0.001, epoch=150, batch_size=2048, nc=57,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.numpyModel = numpyModel(model_name)\n",
    "        self.msi = msi\n",
    "        self.times = times\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.channel = nc\n",
    "        self.negs = negs\n",
    "        self.parameters = kwargs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = 5\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'methods', 'times', 'folds', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity','precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "\n",
    "            for k in range(k_folds):\n",
    "                ### Train data\n",
    "                # posIndex_train = torch.tensor(torch.nonzero(train_X == 1), dtype=torch.int)\n",
    "                posIndex_train = torch.tensor(index_matrix[:, np.where(poscv != k)[0]]).T\n",
    "                negIndex_train = torch.tensor(neg_matrix[:, np.where(negcv != k)[0]]).T\n",
    "                idxs_train = torch.cat((posIndex_train, negIndex_train), dim=0)\n",
    "                # print(idxs_train)\n",
    "                # print(idxs_train.shape)\n",
    "                poslabel_train = torch.ones(posIndex_train.shape[0])\n",
    "                neglabel_train = torch.zeros(negIndex_train.shape[0])\n",
    "                labels_train = torch.cat((poslabel_train, neglabel_train), dim=0)\n",
    "                # print(labels_train.shape)\n",
    "\n",
    "                ### 划分验证集\n",
    "                idxs = idxs_train.numpy().astype(int)\n",
    "                vals = labels_train.numpy().astype(float)\n",
    "                # print(idxs,vals)\n",
    "                # print(idxs.shape, vals.shape)\n",
    "                idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                # idxs_train, idxs_val, labels_train, labels_val = train_test_split(idxs_train, labels_train, test_size=0.1)\n",
    "\n",
    "                ### Test data\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = torch.cat((posIndex_test, negIndex_test), dim=0)\n",
    "                # print(idxs_test)\n",
    "                # print(idxs_test.shape)\n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                # print(labels_test.shape)\n",
    "\n",
    "                # 模型超参数\n",
    "                shape = self.drug_drug_data.X.shape\n",
    "                rank = self.parameters['r']\n",
    "                nc = self.channel\n",
    "                lr = self.lr\n",
    "                epochs = self.epoch\n",
    "                batch_size = self.batch_size\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                methodList = [20, 70, 80, 90]\n",
    "                mnameList = ['Costco', 'DeepSynergy', 'DTF', 'CTF_DDI']\n",
    "\n",
    "                ### 构建深度非线性模型 ### 定义损失函数 和 优化器\n",
    "                if self.msi == 20:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    Neural_Model = Costco(shape, rank, nc, device).to(device)  # Costco\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 70:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    ### 获得三个维度的相似度特征\n",
    "                    M = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    C = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    D = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "                    # M, C, D = getSimFeature(folder=folder, signal=11)\n",
    "                    # M = torch.FloatTensor(M)\n",
    "                    # C = torch.FloatTensor(C)\n",
    "                    # D = torch.FloatTensor(D)\n",
    "                    # inputSize= (M.shape[1]+C.shape[1]+D.shape[1])\n",
    "                    # print(inputSize)\n",
    "                    \n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "                    norm = 'tanh'    \n",
    "                    ## training \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_val, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_tr, mean, std, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, feat_filt = normalize_Deepsynergy(X_val, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "\n",
    "                    #print(X_tr.shape,X_val.shape)\n",
    "                    ## testing    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_train, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_test, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_train, mean, std, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, feat_filt = normalize_Deepsynergy(X_test, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                 \n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DeepSynergy_new(shape, rank, inputSize, \n",
    "                                               X_tr,X_val,X_train,X_test,\n",
    "                                               act_func=nn.ReLU(),dropout=0.5, input_dropout=0.2,\n",
    "                                               dims=[8182, 4096, 1]).to(device)\n",
    "                    # [8182, 4096, 1];[4096, 2048, 1]\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    # optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "                    optimizer = optim.SGD(Neural_Model.parameters(), lr=lr, momentum=0.5)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                        # label_pre=outputs\n",
    "                        # label_pre[ label_pre < threshold ] = 0\n",
    "                        # label_pre[ label_pre >= threshold ] = 1\n",
    "                        # outputs[ outputs < 30 ] = 0\n",
    "                        # outputs[ outputs >= 30 ] = 1\n",
    "                        # labels_test [labels_test<30] = 0\n",
    "                        # labels_test [labels_test >=30] =1\n",
    "                        #print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 80:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embM_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    M = emb.values\n",
    "                    #M = torch.FloatTensor(M).to(device)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embC_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    C = emb.values\n",
    "                    #C = torch.FloatTensor(C).to(device)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embD_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    D = emb.values\n",
    "                    #D = torch.FloatTensor(D).to(device)\n",
    "                    print(M.shape,C.shape,D.shape)\n",
    "\n",
    "                    M = torch.FloatTensor(M)\n",
    "                    C = torch.FloatTensor(C)\n",
    "                    D = torch.FloatTensor(D)\n",
    "                    ### 得到数据集的特征\n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    ### 数据特征标准化\n",
    "                    norm = 'tanh'    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2 = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2 = normalize_DTF(X_val, mean, std, mean2, std2,  norm=norm)\n",
    "                        X_test, mean, std, mean2, std2 = normalize_DTF(X_test, mean, std, mean2, std2, norm=norm)    \n",
    "                    else:\n",
    "                        X_tr, mean, std = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std = normalize_DTF(X_val, mean, std, norm=norm)\n",
    "                        X_test, mean, std = normalize_DTF(X_test, mean, std, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    print(labels_train1,labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    ## 3000\n",
    "                    #inputSize = rank * len(shape)\n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DTF_new(shape, rank, inputSize, embeds=[M, C, D], nn_struc=[2048, 1024, 512],\n",
    "                                       input_dp=0.2, first_dp=0.5, second_dp=0.5).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    criterion = nn.BCELoss()  # binary crossentropy loss\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                    \n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            #print(inputs[-1])\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    #labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                \n",
    "                elif self.msi == 90:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "\n",
    "                    # tl.set_backend('numpy')\n",
    "                    # train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                    # trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                    # train_tensor[trainpos_index] = 0\n",
    "                    # S1 = np.mat(self.drug_drug_data.S1)\n",
    "                    # S2 = np.mat(self.drug_drug_data.S2)\n",
    "                    # _, M, C, D = self.numpyModel()(train_tensor, S1, S2,\n",
    "                    #                                r=self.parameters['r'],\n",
    "                    #                                mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                    #                                alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                    #                                lam=self.parameters['lam'],\n",
    "                    #                                tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                    #                                )\n",
    "                    # print('CTF')\n",
    "                    # # print(M.shape, C.shape, D.shape)\n",
    "                    # M = torch.FloatTensor(M).to(device)\n",
    "                    # C = torch.FloatTensor(C).to(device)\n",
    "                    # D = torch.FloatTensor(D).to(device)\n",
    "                    # print(M.shape, C.shape, D.shape)\n",
    "                    # print(M)\n",
    "\n",
    "                    ### 直接导入提前学习好的因子矩阵 \n",
    "                    fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    #fname='/mnt/sda/liupei/NCTF/newCode/hmddv32/compare/neg/CTF_embeds/1n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "                        M, C, D = pickle.load(f)\n",
    "                    \n",
    "                    M = torch.FloatTensor(M).to(device)\n",
    "                    C = torch.FloatTensor(C).to(device)\n",
    "                    D = torch.FloatTensor(D).to(device)\n",
    "                    \n",
    "                    Neural_Model = CTF_DDI(shape, rank, hids_size=[256, 256, 128], embeds=[M, C, D], device=device).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([testModel,idxs_test,labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                # print(idxs_test.T)\n",
    "                # print(idxs_test.T[0],len(idxs_test.T[0]))\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test.T[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test.T[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test.T[0],\n",
    "                    'm2': idxs_test.T[1],\n",
    "                    'd': idxs_test.T[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': outputs.T[0].cpu().numpy()  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "                \n",
    "                metrics = self.get_metrics_1(labels_test.cpu().numpy(), outputs.T[0].cpu().numpy())\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, mname, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j = j + 1\n",
    "\n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t', i + 1, ':\\t', result)\n",
    "            avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "\n",
    "        fname = os.path.join('compareTF', mname + '_hmddv3.2_'+str(self.negs)+'neg_results_0.5lam_fixed.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        #print(j)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t', results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t', results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score = np.mat(real_score)\n",
    "        predict_score = np.mat(predict_score)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "\n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "\n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "\n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "\n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "\n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "\n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    ### 导入数据\n",
    "    since = time.time()\n",
    "    #df = pd.DataFrame(columns=['methods', 'times', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    methodList = [20, 70, 80, 90]\n",
    "    mnameList = ['Costco', 'DeepSynergy','DTF', 'CTF_DDI']\n",
    "    ## 设置参数\n",
    "    lr = 0.0001  ## 设置均不同\n",
    "    batch_size = 1024\n",
    "    epoch = 500\n",
    "    shape = 3\n",
    "    r = 57\n",
    "    nc = int(2*r)\n",
    "    times = 5\n",
    "    folds = 5\n",
    "    #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    #signal = 11\n",
    "    miRNA_num=351\n",
    "    disease_num=325\n",
    "    #drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "    mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    i = 0\n",
    "    for msi in [20]:\n",
    "        mname = mnameList[methodList.index(msi)]\n",
    "        print(mname, msi)\n",
    "        #for neg in [1,2,4,6,8,10]:\n",
    "        for neg in [1]:\n",
    "            folder = '/mnt/sda/liupei/NCTF_new/data/hmddv32_neg/'+str(neg)+'n'\n",
    "            signal = 11\n",
    "            print(neg)\n",
    "            drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num,filefolder=folder,signal=signal,neg=neg)\n",
    "            since1 = time.time()\n",
    "            if msi == 20:\n",
    "                ## Costco\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',msi=msi, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=500, batch_size=256, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 70:\n",
    "                ### DeepSynergy DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=70, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=64, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "    \n",
    "            elif msi == 80:\n",
    "                ## DTF batch_size=128 r=1000\n",
    "                ### DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=80, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=128, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 90:\n",
    "                ## CTF_DDI batch_size=1000 epoch=300 r=51 max_iter=200\n",
    "                signal = 21  # 22\n",
    "                drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal,neg=neg)\n",
    "                # DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='CTF',\n",
    "                                         msi=90, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=300, batch_size=1000, nc=nc,\n",
    "                                         r=r, mu=0.5, eta=0.2, alpha=0.5, beta=0.5,lam=0.5, tol=1e-6, max_iter=100)\n",
    "\n",
    "            aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "            df.loc[i] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "            # experiment.CV_triplet()[0]\n",
    "            print(f\"i={i}\\ttimes={times}\\tmethods={mname}\\tmsi={msi}\\tneg={neg}\")\n",
    "            print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "            i = i + 1\n",
    "            time_elapsed1 = time.time() - since1\n",
    "            print(time_elapsed1 // 60, time_elapsed1 % 60)\n",
    "            \n",
    "    df.to_csv('Costco_negResults_256.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4aa92fc-f84d-49f6-bfb5-ea95546e731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSynergy 70\n",
      "1\n",
      "(351, 351)\n",
      "(325, 325)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(351, 351, 325)\n",
      "14679.0\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▏                                                                                                   | 147/1000 [03:45<21:46,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.072138\n",
      "tensor([[ 0.9746],\n",
      "        [ 0.7280],\n",
      "        [ 0.8086],\n",
      "        ...,\n",
      "        [ 0.0974],\n",
      "        [-0.0368],\n",
      "        [-0.4216]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_0_times_0_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▊                                                                                               | 186/1000 [04:43<20:41,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.072162\n",
      "tensor([[ 0.5657],\n",
      "        [ 0.6240],\n",
      "        [ 0.6703],\n",
      "        ...,\n",
      "        [ 0.5988],\n",
      "        [-0.2978],\n",
      "        [-0.1317]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_0_times_1_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▊                                                                                                  | 161/1000 [04:06<21:22,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.074525\n",
      "tensor([[ 0.5861],\n",
      "        [ 0.4674],\n",
      "        [ 0.8072],\n",
      "        ...,\n",
      "        [ 0.1050],\n",
      "        [ 0.3705],\n",
      "        [-0.2008]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_0_times_2_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████▊                                                                                                            | 83/1000 [02:03<22:47,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.077082\n",
      "tensor([[ 0.4364],\n",
      "        [ 0.5673],\n",
      "        [ 0.8237],\n",
      "        ...,\n",
      "        [ 0.0295],\n",
      "        [-0.0092],\n",
      "        [ 0.1391]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_0_times_3_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21139, 3)\n",
      "torch.Size([21139, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([23488, 1027])\n",
      "torch.Size([5870, 3])\n",
      "torch.Size([5870, 1027])\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▌                                                                                                   | 150/1000 [03:47<21:31,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.071762\n",
      "tensor([[ 0.4231],\n",
      "        [ 0.5734],\n",
      "        [ 0.6773],\n",
      "        ...,\n",
      "        [-0.1418],\n",
      "        [ 0.0896],\n",
      "        [ 0.3175]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.9789 0.978  0.9267 0.9268 0.9257 0.9279 0.9278]]\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▎                                                                                                   | 148/1000 [03:47<21:49,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.072773\n",
      "tensor([[0.4337],\n",
      "        [0.7555],\n",
      "        [0.8317],\n",
      "        ...,\n",
      "        [0.1103],\n",
      "        [0.1356],\n",
      "        [0.1668]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_1_times_0_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▏                                                                                                    | 138/1000 [03:23<21:13,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.074655\n",
      "tensor([[ 0.5018],\n",
      "        [ 0.6377],\n",
      "        [ 0.6796],\n",
      "        ...,\n",
      "        [-0.2286],\n",
      "        [ 0.0024],\n",
      "        [-0.0267]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_1_times_1_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▉                                                                                                | 179/1000 [04:33<20:54,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.067825\n",
      "tensor([[ 0.4990],\n",
      "        [ 0.9338],\n",
      "        [ 0.8128],\n",
      "        ...,\n",
      "        [ 0.3697],\n",
      "        [-0.0351],\n",
      "        [ 0.3479]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_1_times_2_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▍                                                                                                  | 158/1000 [03:57<21:06,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.073090\n",
      "tensor([[8.0050e-01],\n",
      "        [8.8961e-01],\n",
      "        [7.0637e-01],\n",
      "        ...,\n",
      "        [5.9292e-01],\n",
      "        [1.6610e-04],\n",
      "        [1.2770e-01]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_1_times_3_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21139, 3)\n",
      "torch.Size([21139, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([23488, 1027])\n",
      "torch.Size([5870, 3])\n",
      "torch.Size([5870, 1027])\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▋                                                                                                    | 143/1000 [03:56<23:39,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.074495\n",
      "tensor([[ 0.6788],\n",
      "        [ 0.5242],\n",
      "        [ 0.7109],\n",
      "        ...,\n",
      "        [ 0.1468],\n",
      "        [ 0.4697],\n",
      "        [-0.0311]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.9787 0.9783 0.9279 0.9276 0.9317 0.9235 0.9245]]\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▉                                                                                                    | 145/1000 [05:26<32:04,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.075319\n",
      "tensor([[ 5.5291e-01],\n",
      "        [ 7.6643e-01],\n",
      "        [ 1.0115e+00],\n",
      "        ...,\n",
      "        [ 4.0037e-01],\n",
      "        [-2.5247e-01],\n",
      "        [ 4.1441e-04]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_2_times_0_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▌                                                                                                  | 159/1000 [06:05<32:14,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.070774\n",
      "tensor([[0.7833],\n",
      "        [0.8779],\n",
      "        [0.9432],\n",
      "        ...,\n",
      "        [0.1734],\n",
      "        [0.4865],\n",
      "        [0.1921]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_2_times_1_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▎                                                                                                     | 131/1000 [05:45<38:09,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.074039\n",
      "tensor([[ 0.5636],\n",
      "        [ 1.0884],\n",
      "        [ 0.8129],\n",
      "        ...,\n",
      "        [ 0.6965],\n",
      "        [-0.0575],\n",
      "        [ 0.3403]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_2_times_2_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▋                                                                                                   | 151/1000 [06:38<37:17,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.073795\n",
      "tensor([[0.5376],\n",
      "        [0.8087],\n",
      "        [0.7437],\n",
      "        ...,\n",
      "        [0.3356],\n",
      "        [0.1592],\n",
      "        [0.0202]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_2_times_3_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21139, 3)\n",
      "torch.Size([21139, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([23488, 1027])\n",
      "torch.Size([5870, 3])\n",
      "torch.Size([5870, 1027])\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▌                                                                                                  | 159/1000 [06:16<33:10,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.073104\n",
      "tensor([[ 0.4751],\n",
      "        [ 0.3635],\n",
      "        [ 0.7013],\n",
      "        ...,\n",
      "        [ 0.2148],\n",
      "        [ 0.2141],\n",
      "        [-0.2121]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.979  0.978  0.9279 0.9275 0.9319 0.9232 0.924 ]]\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████                                                                                                   | 154/1000 [05:32<30:25,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.072841\n",
      "tensor([[ 0.3493],\n",
      "        [ 0.7119],\n",
      "        [ 0.8909],\n",
      "        ...,\n",
      "        [-0.0430],\n",
      "        [ 0.1250],\n",
      "        [ 0.0840]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_3_times_0_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████▌                                                                                                           | 89/1000 [03:38<37:18,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.084283\n",
      "tensor([[0.5556],\n",
      "        [0.8290],\n",
      "        [0.7434],\n",
      "        ...,\n",
      "        [0.4649],\n",
      "        [0.3782],\n",
      "        [0.3193]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_3_times_1_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▌                                                                                                   | 150/1000 [06:17<35:40,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.071942\n",
      "tensor([[0.3087],\n",
      "        [0.7323],\n",
      "        [0.7880],\n",
      "        ...,\n",
      "        [0.3219],\n",
      "        [0.5111],\n",
      "        [0.0588]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_3_times_2_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▎                                                                                                    | 139/1000 [06:03<37:29,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.073256\n",
      "tensor([[ 0.6921],\n",
      "        [ 0.9339],\n",
      "        [ 0.7182],\n",
      "        ...,\n",
      "        [-0.2778],\n",
      "        [ 0.0660],\n",
      "        [ 0.4590]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_3_times_3_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21139, 3)\n",
      "torch.Size([21139, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([23488, 1027])\n",
      "torch.Size([5870, 3])\n",
      "torch.Size([5870, 1027])\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▌                                                                                                     | 133/1000 [05:48<37:54,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.073172\n",
      "tensor([[ 0.5333],\n",
      "        [ 0.7511],\n",
      "        [ 0.6790],\n",
      "        ...,\n",
      "        [-0.1328],\n",
      "        [ 0.1390],\n",
      "        [ 0.4154]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.9777 0.9772 0.9263 0.9262 0.9267 0.9257 0.9259]]\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▉                                                                                                   | 153/1000 [06:42<37:06,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.071360\n",
      "tensor([[ 0.6065],\n",
      "        [ 0.8363],\n",
      "        [ 0.8455],\n",
      "        ...,\n",
      "        [ 0.0500],\n",
      "        [-0.0489],\n",
      "        [ 0.2980]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_4_times_0_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▊                                                                                                     | 135/1000 [04:37<29:35,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.073148\n",
      "tensor([[0.4293],\n",
      "        [0.5344],\n",
      "        [0.9737],\n",
      "        ...,\n",
      "        [0.0333],\n",
      "        [0.3114],\n",
      "        [0.1386]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_4_times_1_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▌                                                                                                   | 150/1000 [06:19<35:53,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.070167\n",
      "tensor([[ 0.4989],\n",
      "        [ 0.6365],\n",
      "        [ 0.5166],\n",
      "        ...,\n",
      "        [ 0.0115],\n",
      "        [-0.0994],\n",
      "        [ 0.0376]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_4_times_2_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21137, 3)\n",
      "torch.Size([21137, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([23486, 1027])\n",
      "torch.Size([5872, 3])\n",
      "torch.Size([5872, 1027])\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "(21137, 1027) (2349, 1027) (23486, 1027) (5872, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▉                                                                                                  | 162/1000 [06:50<35:23,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.072650\n",
      "tensor([[0.7013],\n",
      "        [0.9574],\n",
      "        [0.7751],\n",
      "        ...,\n",
      "        [0.0913],\n",
      "        [0.1622],\n",
      "        [0.1239]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_4_times_3_foldscores.pkl\n",
      "DeepSynergy\n",
      "(21139, 3)\n",
      "torch.Size([21139, 1027])\n",
      "(2349, 3)\n",
      "torch.Size([2349, 1027])\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([23488, 1027])\n",
      "torch.Size([5870, 3])\n",
      "torch.Size([5870, 1027])\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "(21139, 1027) (2349, 1027) (23488, 1027) (5870, 1027)\n",
      "DeepSynergy_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1027, out_features=8182, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=8182, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▏                                                                                                  | 155/1000 [06:49<37:10,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.071830\n",
      "tensor([[0.5092],\n",
      "        [0.8848],\n",
      "        [0.8394],\n",
      "        ...,\n",
      "        [0.2347],\n",
      "        [0.0758],\n",
      "        [0.1849]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DeepSynergy_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.9796 0.9788 0.928  0.928  0.9289 0.9271 0.9274]]\n",
      "final:\t [[0.9788 0.9781 0.9274 0.9272 0.929  0.9255 0.9259]]\n",
      "i=0\ttimes=5\tmethods=DeepSynergy\tmsi=70\tneg=1\n",
      "auc=0.9781\taupr=0.9788\tf1=0.9274\tacc=0.9272\trecall=0.929\tspe=0.9255\tpre=0.9259\n",
      "\n",
      "127.0 23.297795295715332\n",
      "127.0 23.490610361099243\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "from DataCombine_neg import GetData\n",
    "from ourMethod_gpu import Model\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_16, NCTF_ConvKAN_16_noeca1, NCTF_ConvKAN_16_noeca2, NCTF_ConvKAN_16_noeca12\n",
    "from newNCTF_NN_2 import NCTF_ConvMLP_16\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_13, NCTF_ConvKAN_1, ConvKAN\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_17, NCTF_ConvKAN_11, ConvKAN_1\n",
    "from newNCTF_NN_2 import Costco\n",
    "from newNCTF_NN_2 import CTF_DDI\n",
    "from newNCTF_NN_2 import DeepSynergy_new, DTF_new\n",
    "from compareNumpyMethod import Model as numpyModel\n",
    "#from DataCombine_drug import GetData\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.backends import cudnn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "import math\n",
    "import time\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "\n",
    "# from utils import draw\n",
    "\n",
    "# tl.set_backend('pytorch')\n",
    "\n",
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "def normalize_Deepsynergy(X, means1=None, std1=None, means2=None, std2=None, feat_filt=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    if feat_filt is None:\n",
    "        feat_filt = std1!=0\n",
    "    X = X[:,feat_filt]\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1[feat_filt]\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1, feat_filt)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1, feat_filt)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        X[:,std2==0]=0\n",
    "        return(X, means1, std1, means2, std2, feat_filt)      \n",
    "\n",
    "def normalize_DTF(X, means1=None, std1=None, means2=None, std2=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if norm is None:\n",
    "        return (X, means1, std1, feat_filt)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        return(X, means1, std1, means2, std2)\n",
    "        \n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', msi=10, times=10, negs=1,\n",
    "                 lr=0.001, epoch=150, batch_size=2048, nc=57,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.numpyModel = numpyModel(model_name)\n",
    "        self.msi = msi\n",
    "        self.times = times\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.channel = nc\n",
    "        self.negs = negs\n",
    "        self.parameters = kwargs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = 5\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'methods', 'times', 'folds', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity','precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "\n",
    "            for k in range(k_folds):\n",
    "                ### Train data\n",
    "                # posIndex_train = torch.tensor(torch.nonzero(train_X == 1), dtype=torch.int)\n",
    "                posIndex_train = torch.tensor(index_matrix[:, np.where(poscv != k)[0]]).T\n",
    "                negIndex_train = torch.tensor(neg_matrix[:, np.where(negcv != k)[0]]).T\n",
    "                idxs_train = torch.cat((posIndex_train, negIndex_train), dim=0)\n",
    "                # print(idxs_train)\n",
    "                # print(idxs_train.shape)\n",
    "                poslabel_train = torch.ones(posIndex_train.shape[0])\n",
    "                neglabel_train = torch.zeros(negIndex_train.shape[0])\n",
    "                labels_train = torch.cat((poslabel_train, neglabel_train), dim=0)\n",
    "                # print(labels_train.shape)\n",
    "\n",
    "                ### 划分验证集\n",
    "                idxs = idxs_train.numpy().astype(int)\n",
    "                vals = labels_train.numpy().astype(float)\n",
    "                # print(idxs,vals)\n",
    "                # print(idxs.shape, vals.shape)\n",
    "                idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                # idxs_train, idxs_val, labels_train, labels_val = train_test_split(idxs_train, labels_train, test_size=0.1)\n",
    "\n",
    "                ### Test data\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = torch.cat((posIndex_test, negIndex_test), dim=0)\n",
    "                # print(idxs_test)\n",
    "                # print(idxs_test.shape)\n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                # print(labels_test.shape)\n",
    "\n",
    "                # 模型超参数\n",
    "                shape = self.drug_drug_data.X.shape\n",
    "                rank = self.parameters['r']\n",
    "                nc = self.channel\n",
    "                lr = self.lr\n",
    "                epochs = self.epoch\n",
    "                batch_size = self.batch_size\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                methodList = [20, 70, 80, 90]\n",
    "                mnameList = ['Costco', 'DeepSynergy', 'DTF', 'CTF_DDI']\n",
    "\n",
    "                ### 构建深度非线性模型 ### 定义损失函数 和 优化器\n",
    "                if self.msi == 20:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    Neural_Model = Costco(shape, rank, nc, device).to(device)  # Costco\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 70:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    ### 获得三个维度的相似度特征\n",
    "                    M = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    C = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    D = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "                    # M, C, D = getSimFeature(folder=folder, signal=11)\n",
    "                    # M = torch.FloatTensor(M)\n",
    "                    # C = torch.FloatTensor(C)\n",
    "                    # D = torch.FloatTensor(D)\n",
    "                    # inputSize= (M.shape[1]+C.shape[1]+D.shape[1])\n",
    "                    # print(inputSize)\n",
    "                    \n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "                    norm = 'tanh'    \n",
    "                    ## training \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_val, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_tr, mean, std, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, feat_filt = normalize_Deepsynergy(X_val, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "\n",
    "                    #print(X_tr.shape,X_val.shape)\n",
    "                    ## testing    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_train, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_test, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_train, mean, std, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, feat_filt = normalize_Deepsynergy(X_test, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                 \n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DeepSynergy_new(shape, rank, inputSize, \n",
    "                                               X_tr,X_val,X_train,X_test,\n",
    "                                               act_func=nn.ReLU(),dropout=0.5, input_dropout=0.2,\n",
    "                                               dims=[8182, 4096, 1]).to(device)\n",
    "                    # [8182, 4096, 1];[4096, 2048, 1]\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    # optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "                    optimizer = optim.SGD(Neural_Model.parameters(), lr=lr, momentum=0.5)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                        # label_pre=outputs\n",
    "                        # label_pre[ label_pre < threshold ] = 0\n",
    "                        # label_pre[ label_pre >= threshold ] = 1\n",
    "                        # outputs[ outputs < 30 ] = 0\n",
    "                        # outputs[ outputs >= 30 ] = 1\n",
    "                        # labels_test [labels_test<30] = 0\n",
    "                        # labels_test [labels_test >=30] =1\n",
    "                        #print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 80:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embM_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    M = emb.values\n",
    "                    #M = torch.FloatTensor(M).to(device)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embC_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    C = emb.values\n",
    "                    #C = torch.FloatTensor(C).to(device)\n",
    "                    fname = os.path.join('./cpwopt_57R/output/', 'embD_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    D = emb.values\n",
    "                    #D = torch.FloatTensor(D).to(device)\n",
    "                    print(M.shape,C.shape,D.shape)\n",
    "\n",
    "                    M = torch.FloatTensor(M)\n",
    "                    C = torch.FloatTensor(C)\n",
    "                    D = torch.FloatTensor(D)\n",
    "                    ### 得到数据集的特征\n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    ### 数据特征标准化\n",
    "                    norm = 'tanh'    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2 = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2 = normalize_DTF(X_val, mean, std, mean2, std2,  norm=norm)\n",
    "                        X_test, mean, std, mean2, std2 = normalize_DTF(X_test, mean, std, mean2, std2, norm=norm)    \n",
    "                    else:\n",
    "                        X_tr, mean, std = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std = normalize_DTF(X_val, mean, std, norm=norm)\n",
    "                        X_test, mean, std = normalize_DTF(X_test, mean, std, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    print(labels_train1,labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    ## 3000\n",
    "                    #inputSize = rank * len(shape)\n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DTF_new(shape, rank, inputSize, embeds=[M, C, D], nn_struc=[2048, 1024, 512],\n",
    "                                       input_dp=0.2, first_dp=0.5, second_dp=0.5).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    criterion = nn.BCELoss()  # binary crossentropy loss\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                    \n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            #print(inputs[-1])\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    #labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                \n",
    "                elif self.msi == 90:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "\n",
    "                    # tl.set_backend('numpy')\n",
    "                    # train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                    # trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                    # train_tensor[trainpos_index] = 0\n",
    "                    # S1 = np.mat(self.drug_drug_data.S1)\n",
    "                    # S2 = np.mat(self.drug_drug_data.S2)\n",
    "                    # _, M, C, D = self.numpyModel()(train_tensor, S1, S2,\n",
    "                    #                                r=self.parameters['r'],\n",
    "                    #                                mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                    #                                alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                    #                                lam=self.parameters['lam'],\n",
    "                    #                                tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                    #                                )\n",
    "                    # print('CTF')\n",
    "                    # # print(M.shape, C.shape, D.shape)\n",
    "                    # M = torch.FloatTensor(M).to(device)\n",
    "                    # C = torch.FloatTensor(C).to(device)\n",
    "                    # D = torch.FloatTensor(D).to(device)\n",
    "                    # print(M.shape, C.shape, D.shape)\n",
    "                    # print(M)\n",
    "\n",
    "                    ### 直接导入提前学习好的因子矩阵 \n",
    "                    fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    #fname='/mnt/sda/liupei/NCTF/newCode/hmddv32/compare/neg/CTF_embeds/1n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "                        M, C, D = pickle.load(f)\n",
    "                    \n",
    "                    M = torch.FloatTensor(M).to(device)\n",
    "                    C = torch.FloatTensor(C).to(device)\n",
    "                    D = torch.FloatTensor(D).to(device)\n",
    "                    \n",
    "                    Neural_Model = CTF_DDI(shape, rank, hids_size=[256, 256, 128], embeds=[M, C, D], device=device).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([testModel,idxs_test,labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                # print(idxs_test.T)\n",
    "                # print(idxs_test.T[0],len(idxs_test.T[0]))\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test.T[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test.T[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test.T[0],\n",
    "                    'm2': idxs_test.T[1],\n",
    "                    'd': idxs_test.T[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': outputs.T[0].cpu().numpy()  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "                \n",
    "                metrics = self.get_metrics_1(labels_test.cpu().numpy(), outputs.T[0].cpu().numpy())\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, mname, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j = j + 1\n",
    "\n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t', i + 1, ':\\t', result)\n",
    "            avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "\n",
    "        fname = os.path.join('compareTF', mname + '_hmddv3.2_'+str(self.negs)+'neg_results_0.5lam_fixed.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        #print(j)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t', results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t', results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score = np.mat(real_score)\n",
    "        predict_score = np.mat(predict_score)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "\n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "\n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "\n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "\n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "\n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "\n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    ### 导入数据\n",
    "    since = time.time()\n",
    "    #df = pd.DataFrame(columns=['methods', 'times', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    methodList = [20, 70, 80, 90]\n",
    "    mnameList = ['Costco', 'DeepSynergy','DTF', 'CTF_DDI']\n",
    "    ## 设置参数\n",
    "    lr = 0.0001  ## 设置均不同\n",
    "    #batch_size = 256\n",
    "    epoch = 500\n",
    "    shape = 3\n",
    "    r = 57\n",
    "    nc = int(2*r)\n",
    "    times = 5\n",
    "    folds = 5\n",
    "    #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    #signal = 11\n",
    "    miRNA_num=351\n",
    "    disease_num=325\n",
    "    #drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "    mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    i = 0\n",
    "    for msi in [70]:\n",
    "        mname = mnameList[methodList.index(msi)]\n",
    "        print(mname, msi)\n",
    "        #for neg in [1,2,4,6,8,10]:\n",
    "        for neg in [1]:\n",
    "            folder = '/mnt/sda/liupei/NCTF_new/data/hmddv32_neg/'+str(neg)+'n'\n",
    "            signal = 11\n",
    "            print(neg)\n",
    "            drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num,filefolder=folder,signal=signal,neg=neg)\n",
    "            since1 = time.time()\n",
    "            if msi == 20:\n",
    "                ## Costco\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',msi=msi, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=500, batch_size=256, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 70:\n",
    "                ### DeepSynergy DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=70, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=64, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "    \n",
    "            elif msi == 80:\n",
    "                ## DTF batch_size=128 r=1000\n",
    "                ### DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=80, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=128, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 90:\n",
    "                ## CTF_DDI batch_size=1000 epoch=300 r=51 max_iter=200\n",
    "                signal = 21  # 22\n",
    "                drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal,neg=neg)\n",
    "                # DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='CTF',\n",
    "                                         msi=90, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=300, batch_size=1000, nc=nc,\n",
    "                                         r=r, mu=0.5, eta=0.2, alpha=0.5, beta=0.5,lam=0.5, tol=1e-6, max_iter=100)\n",
    "\n",
    "            aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "            df.loc[i] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "            # experiment.CV_triplet()[0]\n",
    "            print(f\"i={i}\\ttimes={times}\\tmethods={mname}\\tmsi={msi}\\tneg={neg}\")\n",
    "            print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "            i = i + 1\n",
    "            time_elapsed1 = time.time() - since1\n",
    "            print(time_elapsed1 // 60, time_elapsed1 % 60)\n",
    "            \n",
    "    df.to_csv('DeepSynergy_negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0a939e-415d-4422-a374-dd33e3a8e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTF 80\n",
      "1\n",
      "(351, 351)\n",
      "(325, 325)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(351, 351, 325)\n",
      "14679.0\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▌                                                                                              | 193/1000 [03:13<13:28,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.175125\n",
      "tensor([[0.9987],\n",
      "        [0.7194],\n",
      "        [0.9925],\n",
      "        ...,\n",
      "        [0.0871],\n",
      "        [0.0024],\n",
      "        [0.0178]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_0_times_0_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▋                                                                                                    | 143/1000 [02:23<14:20,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.177468\n",
      "tensor([[0.8733],\n",
      "        [0.8491],\n",
      "        [0.9285],\n",
      "        ...,\n",
      "        [0.7201],\n",
      "        [0.0310],\n",
      "        [0.0085]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_0_times_1_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████                                                                                                  | 163/1000 [02:43<14:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.183743\n",
      "tensor([[0.9986],\n",
      "        [0.9944],\n",
      "        [0.9290],\n",
      "        ...,\n",
      "        [0.0095],\n",
      "        [0.0063],\n",
      "        [0.0183]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_0_times_2_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▉                                                                                                   | 153/1000 [02:33<14:08,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.184377\n",
      "tensor([[9.9621e-01],\n",
      "        [9.9233e-01],\n",
      "        [9.3243e-01],\n",
      "        ...,\n",
      "        [2.5386e-02],\n",
      "        [2.7129e-04],\n",
      "        [6.2529e-02]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_0_times_3_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21139, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([5870, 3])\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "tensor([1., 0., 1.,  ..., 0., 0., 1.]) tensor([1., 1., 1.,  ..., 1., 0., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████                                                                                                 | 171/1000 [02:52<13:55,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.173362\n",
      "tensor([[0.9990],\n",
      "        [0.9966],\n",
      "        [0.4221],\n",
      "        ...,\n",
      "        [0.0104],\n",
      "        [0.0025],\n",
      "        [0.0084]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.9835 0.9838 0.9441 0.9437 0.9509 0.9366 0.9376]]\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▊                                                                                                | 178/1000 [02:58<13:43,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.173404\n",
      "tensor([[9.9454e-01],\n",
      "        [9.9205e-01],\n",
      "        [9.9587e-01],\n",
      "        ...,\n",
      "        [4.2223e-04],\n",
      "        [8.9340e-03],\n",
      "        [3.1894e-02]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_1_times_0_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▎                                                                                                  | 156/1000 [02:10<11:48,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.177235\n",
      "tensor([[7.0021e-01],\n",
      "        [7.7193e-01],\n",
      "        [9.8861e-01],\n",
      "        ...,\n",
      "        [2.6471e-05],\n",
      "        [7.7890e-04],\n",
      "        [1.0662e-01]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_1_times_1_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▉                                                                                                   | 153/1000 [01:23<07:42,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.170005\n",
      "tensor([[0.9956],\n",
      "        [0.9697],\n",
      "        [0.7500],\n",
      "        ...,\n",
      "        [0.0940],\n",
      "        [0.0023],\n",
      "        [0.0116]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_1_times_2_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████▏                                                                                                 | 164/1000 [01:38<08:24,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.177089\n",
      "tensor([[0.9862],\n",
      "        [0.9716],\n",
      "        [0.9186],\n",
      "        ...,\n",
      "        [0.0509],\n",
      "        [0.0013],\n",
      "        [0.0150]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_1_times_3_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21139, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([5870, 3])\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "tensor([1., 0., 1.,  ..., 0., 0., 1.]) tensor([1., 1., 1.,  ..., 1., 0., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▎                                                                                               | 182/1000 [02:24<10:51,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.184010\n",
      "tensor([[8.4957e-01],\n",
      "        [8.9391e-02],\n",
      "        [9.9211e-01],\n",
      "        ...,\n",
      "        [3.0531e-03],\n",
      "        [4.6814e-04],\n",
      "        [2.7533e-03]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.9832 0.9838 0.9466 0.9463 0.9511 0.9415 0.9422]]\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▌                                                                                                | 176/1000 [02:22<11:07,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.169335\n",
      "tensor([[0.9616],\n",
      "        [0.9983],\n",
      "        [1.0000],\n",
      "        ...,\n",
      "        [0.4683],\n",
      "        [0.0390],\n",
      "        [0.0010]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_2_times_0_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▊                                                                                               | 186/1000 [02:48<12:16,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.185557\n",
      "tensor([[9.9589e-01],\n",
      "        [9.9833e-01],\n",
      "        [9.9999e-01],\n",
      "        ...,\n",
      "        [4.8241e-05],\n",
      "        [9.8908e-01],\n",
      "        [3.6587e-01]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_2_times_1_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▋                                                                                                   | 151/1000 [02:29<14:01,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.176011\n",
      "tensor([[0.8987],\n",
      "        [0.9998],\n",
      "        [0.7404],\n",
      "        ...,\n",
      "        [0.9985],\n",
      "        [0.0030],\n",
      "        [0.6542]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_2_times_2_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████▉                                                                                                 | 170/1000 [02:46<13:34,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.186641\n",
      "tensor([[0.9331],\n",
      "        [0.9912],\n",
      "        [0.9589],\n",
      "        ...,\n",
      "        [0.9997],\n",
      "        [0.0020],\n",
      "        [0.2219]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_2_times_3_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21139, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([5870, 3])\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "tensor([1., 0., 1.,  ..., 0., 0., 1.]) tensor([1., 1., 1.,  ..., 1., 0., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▊                                                                                                     | 135/1000 [02:13<14:16,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.183413\n",
      "tensor([[9.7122e-01],\n",
      "        [9.8851e-01],\n",
      "        [9.8006e-01],\n",
      "        ...,\n",
      "        [1.3499e-01],\n",
      "        [2.4566e-03],\n",
      "        [5.0476e-05]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.9832 0.9838 0.9458 0.9455 0.951  0.9401 0.9408]]\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▍                                                                                                    | 140/1000 [01:44<10:39,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.191613\n",
      "tensor([[0.9275],\n",
      "        [0.4765],\n",
      "        [0.9811],\n",
      "        ...,\n",
      "        [0.0010],\n",
      "        [0.8934],\n",
      "        [0.0016]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_3_times_0_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████                                                                                                   | 154/1000 [01:27<08:01,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.195897\n",
      "tensor([[0.8875],\n",
      "        [0.9548],\n",
      "        [0.7625],\n",
      "        ...,\n",
      "        [0.0029],\n",
      "        [0.0035],\n",
      "        [0.2235]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_3_times_1_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▎                                                                                                   | 148/1000 [01:57<11:17,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.179679\n",
      "tensor([[0.9448],\n",
      "        [0.8011],\n",
      "        [0.9909],\n",
      "        ...,\n",
      "        [0.0059],\n",
      "        [0.8974],\n",
      "        [0.0037]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_3_times_2_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▋                                                                                                     | 134/1000 [01:58<12:46,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.179593\n",
      "tensor([[0.9988],\n",
      "        [0.8758],\n",
      "        [0.9348],\n",
      "        ...,\n",
      "        [0.0012],\n",
      "        [0.0172],\n",
      "        [0.6124]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_3_times_3_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21139, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([5870, 3])\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "tensor([1., 0., 1.,  ..., 0., 0., 1.]) tensor([1., 1., 1.,  ..., 1., 0., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▊                                                                                                     | 135/1000 [01:59<12:43,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.168569\n",
      "tensor([[6.0907e-02],\n",
      "        [9.7113e-01],\n",
      "        [6.2902e-01],\n",
      "        ...,\n",
      "        [3.8369e-01],\n",
      "        [5.7730e-04],\n",
      "        [3.8995e-03]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.9808 0.9813 0.9401 0.94   0.9412 0.9388 0.939 ]]\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████▊                                                                                         | 238/1000 [03:41<11:49,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.163202\n",
      "tensor([[9.9862e-01],\n",
      "        [8.6024e-01],\n",
      "        [9.9556e-01],\n",
      "        ...,\n",
      "        [5.6763e-04],\n",
      "        [5.0109e-04],\n",
      "        [6.8121e-05]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_4_times_0_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▉                                                                                                    | 145/1000 [02:20<13:49,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.184232\n",
      "tensor([[9.8259e-01],\n",
      "        [9.6559e-01],\n",
      "        [9.5122e-01],\n",
      "        ...,\n",
      "        [2.3893e-03],\n",
      "        [5.8579e-04],\n",
      "        [1.7994e-02]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_4_times_1_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▋                                                                                                  | 160/1000 [02:34<13:32,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.160517\n",
      "tensor([[0.9555],\n",
      "        [0.9610],\n",
      "        [0.4573],\n",
      "        ...,\n",
      "        [0.0029],\n",
      "        [0.0400],\n",
      "        [0.0011]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_4_times_2_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21137, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23486, 3])\n",
      "torch.Size([5872, 3])\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "(21137, 171) (2349, 171) (23486, 171) (5872, 171)\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.]) tensor([1., 0., 1.,  ..., 0., 1., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████▉                                                                                                 | 170/1000 [02:44<13:23,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.188903\n",
      "tensor([[0.5910],\n",
      "        [0.9983],\n",
      "        [0.9938],\n",
      "        ...,\n",
      "        [0.1125],\n",
      "        [0.0660],\n",
      "        [0.0023]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_4_times_3_foldscores.pkl\n",
      "DTF\n",
      "(351, 57) (351, 57) (325, 57)\n",
      "(21139, 3)\n",
      "(2349, 3)\n",
      "torch.Size([23488, 3])\n",
      "torch.Size([5870, 3])\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "(21139, 171) (2349, 171) (23488, 171) (5870, 171)\n",
      "tensor([1., 0., 1.,  ..., 0., 0., 1.]) tensor([1., 1., 1.,  ..., 1., 0., 0.])\n",
      "DTF_new(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=171, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▊                                                                                                  | 161/1000 [02:24<12:35,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.172366\n",
      "tensor([[9.0032e-01],\n",
      "        [9.9936e-01],\n",
      "        [9.9596e-01],\n",
      "        ...,\n",
      "        [2.3687e-04],\n",
      "        [1.2943e-03],\n",
      "        [2.9165e-02]], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "pred_score_pkl/DTF_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.9852 0.9852 0.9469 0.9467 0.9501 0.9434 0.9438]]\n",
      "final:\t [[0.9832 0.9836 0.9447 0.9445 0.9489 0.9401 0.9407]]\n",
      "i=0\ttimes=5\tmethods=DTF\tmsi=80\tneg=1\n",
      "auc=0.9836\taupr=0.9832\tf1=0.9447\tacc=0.9445\trecall=0.9489\tspe=0.9401\tpre=0.9407\n",
      "\n",
      "60.0 1.4734878540039062\n",
      "60.0 1.6929316520690918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "from DataCombine_neg import GetData\n",
    "from ourMethod_gpu import Model\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_16, NCTF_ConvKAN_16_noeca1, NCTF_ConvKAN_16_noeca2, NCTF_ConvKAN_16_noeca12\n",
    "from newNCTF_NN_2 import NCTF_ConvMLP_16\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_13, NCTF_ConvKAN_1, ConvKAN\n",
    "from newNCTF_NN_2 import NCTF_ConvKAN_17, NCTF_ConvKAN_11, ConvKAN_1\n",
    "from newNCTF_NN_2 import Costco\n",
    "from newNCTF_NN_2 import CTF_DDI\n",
    "from newNCTF_NN_2 import DeepSynergy_new, DTF_new\n",
    "from compareNumpyMethod import Model as numpyModel\n",
    "#from DataCombine_drug import GetData\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.backends import cudnn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "import math\n",
    "import time\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "\n",
    "# from utils import draw\n",
    "\n",
    "# tl.set_backend('pytorch')\n",
    "\n",
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "def normalize_Deepsynergy(X, means1=None, std1=None, means2=None, std2=None, feat_filt=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    if feat_filt is None:\n",
    "        feat_filt = std1!=0\n",
    "    X = X[:,feat_filt]\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1[feat_filt]\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1, feat_filt)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1, feat_filt)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        X[:,std2==0]=0\n",
    "        return(X, means1, std1, means2, std2, feat_filt)      \n",
    "\n",
    "def normalize_DTF(X, means1=None, std1=None, means2=None, std2=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    X = np.ascontiguousarray(X)\n",
    "    if norm is None:\n",
    "        return (X, means1, std1, feat_filt)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        return(X, means1, std1, means2, std2)\n",
    "        \n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', msi=10, times=10, negs=1,\n",
    "                 lr=0.001, epoch=150, batch_size=2048, nc=57,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.numpyModel = numpyModel(model_name)\n",
    "        self.msi = msi\n",
    "        self.times = times\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.channel = nc\n",
    "        self.negs = negs\n",
    "        self.parameters = kwargs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = 5\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'methods', 'times', 'folds', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity','precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "\n",
    "            for k in range(k_folds):\n",
    "                ### Train data\n",
    "                # posIndex_train = torch.tensor(torch.nonzero(train_X == 1), dtype=torch.int)\n",
    "                posIndex_train = torch.tensor(index_matrix[:, np.where(poscv != k)[0]]).T\n",
    "                negIndex_train = torch.tensor(neg_matrix[:, np.where(negcv != k)[0]]).T\n",
    "                idxs_train = torch.cat((posIndex_train, negIndex_train), dim=0)\n",
    "                # print(idxs_train)\n",
    "                # print(idxs_train.shape)\n",
    "                poslabel_train = torch.ones(posIndex_train.shape[0])\n",
    "                neglabel_train = torch.zeros(negIndex_train.shape[0])\n",
    "                labels_train = torch.cat((poslabel_train, neglabel_train), dim=0)\n",
    "                # print(labels_train.shape)\n",
    "\n",
    "                ### 划分验证集\n",
    "                idxs = idxs_train.numpy().astype(int)\n",
    "                vals = labels_train.numpy().astype(float)\n",
    "                # print(idxs,vals)\n",
    "                # print(idxs.shape, vals.shape)\n",
    "                idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                # idxs_train, idxs_val, labels_train, labels_val = train_test_split(idxs_train, labels_train, test_size=0.1)\n",
    "\n",
    "                ### Test data\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = torch.cat((posIndex_test, negIndex_test), dim=0)\n",
    "                # print(idxs_test)\n",
    "                # print(idxs_test.shape)\n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                # print(labels_test.shape)\n",
    "\n",
    "                # 模型超参数\n",
    "                shape = self.drug_drug_data.X.shape\n",
    "                rank = self.parameters['r']\n",
    "                nc = self.channel\n",
    "                lr = self.lr\n",
    "                epochs = self.epoch\n",
    "                batch_size = self.batch_size\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                methodList = [20, 70, 80, 90]\n",
    "                mnameList = ['Costco', 'DeepSynergy', 'DTF', 'CTF_DDI']\n",
    "\n",
    "                ### 构建深度非线性模型 ### 定义损失函数 和 优化器\n",
    "                if self.msi == 20:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    Neural_Model = Costco(shape, rank, nc, device).to(device)  # Costco\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 70:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    ### 获得三个维度的相似度特征\n",
    "                    M = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    C = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                    D = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "                    # M, C, D = getSimFeature(folder=folder, signal=11)\n",
    "                    # M = torch.FloatTensor(M)\n",
    "                    # C = torch.FloatTensor(C)\n",
    "                    # D = torch.FloatTensor(D)\n",
    "                    # inputSize= (M.shape[1]+C.shape[1]+D.shape[1])\n",
    "                    # print(inputSize)\n",
    "                    \n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    print(f123.shape)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "                    norm = 'tanh'    \n",
    "                    ## training \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_val, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_tr, mean, std, feat_filt = normalize_Deepsynergy(X_tr, norm=norm)\n",
    "                        X_val, mean, std, feat_filt = normalize_Deepsynergy(X_val, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "\n",
    "                    #print(X_tr.shape,X_val.shape)\n",
    "                    ## testing    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_train, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, mean2, std2, feat_filt = normalize_Deepsynergy(X_test, mean, std, mean2, std2, \n",
    "                                                                              feat_filt=feat_filt, norm=norm)\n",
    "                    else:\n",
    "                        X_train, mean, std, feat_filt = normalize_Deepsynergy(X_train, norm=norm)\n",
    "                        X_test, mean, std, feat_filt = normalize_Deepsynergy(X_test, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                 \n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DeepSynergy_new(shape, rank, inputSize, \n",
    "                                               X_tr,X_val,X_train,X_test,\n",
    "                                               act_func=nn.ReLU(),dropout=0.5, input_dropout=0.2,\n",
    "                                               dims=[8182, 4096, 1]).to(device)\n",
    "                    # [8182, 4096, 1];[4096, 2048, 1]\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    # optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "                    optimizer = optim.SGD(Neural_Model.parameters(), lr=lr, momentum=0.5)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                        # label_pre=outputs\n",
    "                        # label_pre[ label_pre < threshold ] = 0\n",
    "                        # label_pre[ label_pre >= threshold ] = 1\n",
    "                        # outputs[ outputs < 30 ] = 0\n",
    "                        # outputs[ outputs >= 30 ] = 1\n",
    "                        # labels_test [labels_test<30] = 0\n",
    "                        # labels_test [labels_test >=30] =1\n",
    "                        #print(outputs,labels_test)\n",
    "\n",
    "                elif self.msi == 80:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    fname = os.path.join('/mnt/sda/liupei/NCTF_new/hmddv32/compare/neg/cpwopt_57R/'+str(self.negs)+'n/output/'\n",
    "                                         'embM_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    M = emb.values\n",
    "                    #M = torch.FloatTensor(M).to(device)\n",
    "                    fname = os.path.join('/mnt/sda/liupei/NCTF_new/hmddv32/compare/neg/cpwopt_57R/'+str(self.negs)+'n/output/'\n",
    "                                         'embC_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    C = emb.values\n",
    "                    #C = torch.FloatTensor(C).to(device)\n",
    "                    fname = os.path.join('/mnt/sda/liupei/NCTF_new/hmddv32/compare/neg/cpwopt_57R/'+str(self.negs)+'n/output/'\n",
    "                                         'embD_{}_times_{}_fold.csv'.format(i + 1, k + 1))\n",
    "                    emb = pd.read_csv(fname, header=None)\n",
    "                    D = emb.values\n",
    "                    #D = torch.FloatTensor(D).to(device)\n",
    "                    print(M.shape,C.shape,D.shape)\n",
    "\n",
    "                    M = torch.FloatTensor(M)\n",
    "                    C = torch.FloatTensor(C)\n",
    "                    D = torch.FloatTensor(D)\n",
    "                    ### 得到数据集的特征\n",
    "                    print(idxs_train1.shape)\n",
    "                    f_1 = M[idxs_train1.T[0]]\n",
    "                    f_2 = C[idxs_train1.T[1]]\n",
    "                    f_3 = D[idxs_train1.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_tr=f123.numpy()\n",
    "\n",
    "                    print(idxs_val.shape)\n",
    "                    f_1 = M[idxs_val.T[0]]\n",
    "                    f_2 = C[idxs_val.T[1]]\n",
    "                    f_3 = D[idxs_val.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_val=f123.numpy()\n",
    "\n",
    "                    print(idxs_train.shape)\n",
    "                    f_1 = M[idxs_train.T[0]]\n",
    "                    f_2 = C[idxs_train.T[1]]\n",
    "                    f_3 = D[idxs_train.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_train=f123.numpy()\n",
    "\n",
    "                    print(idxs_test.shape)\n",
    "                    f_1 = M[idxs_test.T[0]]\n",
    "                    f_2 = C[idxs_test.T[1]]\n",
    "                    f_3 = D[idxs_test.T[2]]\n",
    "                    f123 = torch.cat([f_1,f_2,f_3], dim=1)\n",
    "                    #print(f123)\n",
    "                    X_test=f123.numpy()\n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    ### 数据特征标准化\n",
    "                    norm = 'tanh'    \n",
    "                    if norm == \"tanh_norm\":\n",
    "                        X_tr, mean, std, mean2, std2 = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std, mean2, std2 = normalize_DTF(X_val, mean, std, mean2, std2,  norm=norm)\n",
    "                        X_test, mean, std, mean2, std2 = normalize_DTF(X_test, mean, std, mean2, std2, norm=norm)    \n",
    "                    else:\n",
    "                        X_tr, mean, std = normalize_DTF(X_tr, norm=norm)\n",
    "                        X_val, mean, std = normalize_DTF(X_val, mean, std, norm=norm)\n",
    "                        X_test, mean, std = normalize_DTF(X_test, mean, std, norm=norm)\n",
    "                    \n",
    "                    print(X_tr.shape,X_val.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "                    # 创建数据加载器\n",
    "                    X_tr = torch.FloatTensor(X_tr)\n",
    "                    X_val = torch.FloatTensor(X_val)\n",
    "                    X_test = torch.FloatTensor(X_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    print(labels_train1,labels_val)\n",
    "                    # labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, labels_train1)\n",
    "                    val_dataset = TensorDataset(X_val, labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "                    \n",
    "                    ## 3000\n",
    "                    #inputSize = rank * len(shape)\n",
    "                    inputSize = X_tr.shape[1]\n",
    "                    Neural_Model = DTF_new(shape, rank, inputSize, embeds=[M, C, D], nn_struc=[2048, 1024, 512],\n",
    "                                       input_dp=0.2, first_dp=0.5, second_dp=0.5).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    Neural_Model.apply(he_init)\n",
    "                    criterion = nn.BCELoss()  # binary crossentropy loss\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                    \n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            #print(inputs[-1])\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                #inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    #labels_test_Score = torch.FloatTensor(labels_test_Score)\n",
    "                    #labels_test = torch.FloatTensor(labels_test)\n",
    "                    #print(labels_test)\n",
    "                    with torch.no_grad():\n",
    "                        #inputs_gpu = idxs_test.T.to(device)\n",
    "                        inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        #loss = criterion(outputs, labels_test_Score.unsqueeze(1).to(device))\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "                \n",
    "                elif self.msi == 90:\n",
    "                    mname = mnameList[methodList.index(self.msi)]\n",
    "                    print(mname)\n",
    "                    # ### 划分验证集\n",
    "                    # idxs = idxs_train.numpy().astype(int)\n",
    "                    # vals = labels_train.numpy().astype(float)\n",
    "                    # # print(idxs,vals)\n",
    "                    # # print(idxs.shape, vals.shape)\n",
    "                    # idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1,random_state=2024)\n",
    "                    \n",
    "                    # 创建数据加载器\n",
    "                    idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                    idxs_val = torch.LongTensor(idxs_val)\n",
    "                    # idxs_test = torch.LongTensor(idxs_test)\n",
    "                    labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                    labels_val = torch.FloatTensor(labels_val)\n",
    "                    # labels_test = torch.FloatTensor(labels_test)\n",
    "                    \n",
    "                    train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                    val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    del train_dataset, val_dataset\n",
    "\n",
    "                    # tl.set_backend('numpy')\n",
    "                    # train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                    # trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                    # train_tensor[trainpos_index] = 0\n",
    "                    # S1 = np.mat(self.drug_drug_data.S1)\n",
    "                    # S2 = np.mat(self.drug_drug_data.S2)\n",
    "                    # _, M, C, D = self.numpyModel()(train_tensor, S1, S2,\n",
    "                    #                                r=self.parameters['r'],\n",
    "                    #                                mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                    #                                alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                    #                                lam=self.parameters['lam'],\n",
    "                    #                                tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                    #                                )\n",
    "                    # print('CTF')\n",
    "                    # # print(M.shape, C.shape, D.shape)\n",
    "                    # M = torch.FloatTensor(M).to(device)\n",
    "                    # C = torch.FloatTensor(C).to(device)\n",
    "                    # D = torch.FloatTensor(D).to(device)\n",
    "                    # print(M.shape, C.shape, D.shape)\n",
    "                    # print(M)\n",
    "\n",
    "                    ### 直接导入提前学习好的因子矩阵 \n",
    "                    fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    #fname='/mnt/sda/liupei/NCTF/newCode/hmddv32/compare/neg/CTF_embeds/1n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                    with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "                        M, C, D = pickle.load(f)\n",
    "                    \n",
    "                    M = torch.FloatTensor(M).to(device)\n",
    "                    C = torch.FloatTensor(C).to(device)\n",
    "                    D = torch.FloatTensor(D).to(device)\n",
    "                    \n",
    "                    Neural_Model = CTF_DDI(shape, rank, hids_size=[256, 256, 128], embeds=[M, C, D], device=device).to(device)\n",
    "                    print(Neural_Model)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    optimizer = optim.Adam(Neural_Model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "                    # 训练模型\n",
    "                    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "                    loss_train_list = []\n",
    "                    loss_test_list = []\n",
    "                    for epoch in tqdm(range(epochs)):\n",
    "                        ##训练\n",
    "                        Neural_Model.train()\n",
    "                        train_loss, valid_loss = 0, 0\n",
    "                        # loss_train_list_batch = []\n",
    "                        for inputs in train_loader:\n",
    "                            #print(inputs)\n",
    "                            optimizer.zero_grad()\n",
    "                            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                            #inputs_gpu = inputs[0].to(device)\n",
    "                            outputs = Neural_Model(inputs_gpu)\n",
    "                            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            train_loss += loss.item() * len(inputs)\n",
    "                        train_loss /= len(train_loader.dataset)\n",
    "                        loss_train_list.append(train_loss)\n",
    "    \n",
    "                        # 验证模型\n",
    "                        Neural_Model.eval()\n",
    "                        val_loss = 0.0\n",
    "                        for inputs in val_loader:\n",
    "                            with torch.no_grad():\n",
    "                                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                                #inputs_gpu = inputs[0].to(device)\n",
    "                                outputs = Neural_Model(inputs_gpu)\n",
    "                                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                                val_loss += loss.item() * len(inputs)\n",
    "                        val_loss /= len(val_loader.dataset)\n",
    "                        loss_test_list.append(val_loss)\n",
    "    \n",
    "                        # if epoch % 5 == 0:\n",
    "                        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "                        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "                            break\n",
    "    \n",
    "                        if min_val > val_loss:\n",
    "                            min_val = val_loss\n",
    "                            min_epoch = epoch\n",
    "                            testModel = Neural_Model\n",
    "                    \n",
    "                    testModel.eval()\n",
    "                    with torch.no_grad():\n",
    "                        inputs_gpu = idxs_test.T.to(device)\n",
    "                        #inputs_gpu = X_test.to(device)\n",
    "                        outputs = testModel(inputs_gpu)\n",
    "                        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "                        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "                        print(outputs,labels_test)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([testModel,idxs_test,labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                # print(idxs_test.T)\n",
    "                # print(idxs_test.T[0],len(idxs_test.T[0]))\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test.T[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test.T[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test.T[0],\n",
    "                    'm2': idxs_test.T[1],\n",
    "                    'd': idxs_test.T[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': outputs.T[0].cpu().numpy()  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "                \n",
    "                metrics = self.get_metrics_1(labels_test.cpu().numpy(), outputs.T[0].cpu().numpy())\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, mname, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j = j + 1\n",
    "\n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t', i + 1, ':\\t', result)\n",
    "            avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "\n",
    "        fname = os.path.join('compareTF', mname + '_hmddv3.2_'+str(self.negs)+'neg_results_0.5lam_fixed.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        #print(j)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t', results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t', results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score = np.mat(real_score)\n",
    "        predict_score = np.mat(predict_score)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "\n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "\n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "\n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "\n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "\n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "\n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    ### 导入数据\n",
    "    since = time.time()\n",
    "    #df = pd.DataFrame(columns=['methods', 'times', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    methodList = [20, 70, 80, 90]\n",
    "    mnameList = ['Costco', 'DeepSynergy','DTF', 'CTF_DDI']\n",
    "    ## 设置参数\n",
    "    lr = 0.0001  ## 设置均不同\n",
    "    #batch_size = 256\n",
    "    epoch = 500\n",
    "    shape = 3\n",
    "    r = 57\n",
    "    nc = int(2*r)\n",
    "    times = 5\n",
    "    folds = 5\n",
    "    #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    #signal = 11\n",
    "    miRNA_num=351\n",
    "    disease_num=325\n",
    "    #drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "    mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    i = 0\n",
    "    for msi in [80]:\n",
    "        mname = mnameList[methodList.index(msi)]\n",
    "        print(mname, msi)\n",
    "        #for neg in [1,2,4,6,8,10]:\n",
    "        for neg in [1]:\n",
    "            folder = '/mnt/sda/liupei/NCTF_new/data/hmddv32_neg/'+str(neg)+'n'\n",
    "            signal = 11\n",
    "            print(neg)\n",
    "            drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num,filefolder=folder,signal=signal,neg=neg)\n",
    "            since1 = time.time()\n",
    "            if msi == 20:\n",
    "                ## Costco\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',msi=msi, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=500, batch_size=256, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 70:\n",
    "                ### DeepSynergy DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=70, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=64, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "    \n",
    "            elif msi == 80:\n",
    "                ## DTF batch_size=128 r=1000\n",
    "                ### DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32',\n",
    "                                         msi=80, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.00001, epoch=1000, batch_size=128, nc=nc,\n",
    "                                         r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol=1e-4, max_iter=100)\n",
    "            elif msi == 90:\n",
    "                ## CTF_DDI batch_size=1000 epoch=300 r=51 max_iter=200\n",
    "                signal = 21  # 22\n",
    "                drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal,neg=neg)\n",
    "                # DTF 论文设置的参数\n",
    "                experiment = Experiments(drug_drug_data, model_name='CTF',\n",
    "                                         msi=90, times=times, folds=folds,negs=neg,\n",
    "                                         lr=0.0001, epoch=300, batch_size=1000, nc=nc,\n",
    "                                         r=r, mu=0.5, eta=0.2, alpha=0.5, beta=0.5,lam=0.5, tol=1e-6, max_iter=100)\n",
    "\n",
    "            aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "            df.loc[i] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "            # experiment.CV_triplet()[0]\n",
    "            print(f\"i={i}\\ttimes={times}\\tmethods={mname}\\tmsi={msi}\\tneg={neg}\")\n",
    "            print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "            i = i + 1\n",
    "            time_elapsed1 = time.time() - since1\n",
    "            print(time_elapsed1 // 60, time_elapsed1 % 60)\n",
    "            \n",
    "    df.to_csv('DTF_negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810adcd5-b342-46d2-bc65-3ac1ac811f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
