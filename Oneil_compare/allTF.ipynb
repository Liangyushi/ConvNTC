{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c495a88e-5ff3-4f39-9e0d-0dd74eab59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38)\n",
      "(39, 39)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(38, 38, 39)\n",
      "4014.0\n",
      "(38, 38, 39)\n",
      "0 fold end!\n",
      "NCTF_embeds/factors_0_times_0_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_0_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "NCTF_embeds/factors_0_times_1_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_0_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "NCTF_embeds/factors_0_times_2_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_0_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "NCTF_embeds/factors_0_times_3_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_0_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "NCTF_embeds/factors_0_times_4_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.7595 0.9516 0.6969 0.947  0.6916 0.9717 0.7042]]\n",
      "9.0 11.384522676467896\n",
      "0 fold end!\n",
      "NCTF_embeds/factors_1_times_0_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_1_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "NCTF_embeds/factors_1_times_1_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_1_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "NCTF_embeds/factors_1_times_2_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_1_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "NCTF_embeds/factors_1_times_3_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_1_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "NCTF_embeds/factors_1_times_4_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.7545 0.9492 0.6956 0.9472 0.6836 0.9727 0.7089]]\n",
      "9.0 41.29056906700134\n",
      "0 fold end!\n",
      "NCTF_embeds/factors_2_times_0_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_2_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "NCTF_embeds/factors_2_times_1_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_2_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "NCTF_embeds/factors_2_times_2_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_2_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "NCTF_embeds/factors_2_times_3_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_2_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "NCTF_embeds/factors_2_times_4_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.7662 0.9502 0.7038 0.9469 0.7147 0.9693 0.694 ]]\n",
      "9.0 32.460240602493286\n",
      "0 fold end!\n",
      "NCTF_embeds/factors_3_times_0_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_3_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "NCTF_embeds/factors_3_times_1_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_3_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "NCTF_embeds/factors_3_times_2_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_3_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "NCTF_embeds/factors_3_times_3_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_3_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "NCTF_embeds/factors_3_times_4_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.766  0.9481 0.7011 0.9482 0.6883 0.9734 0.7149]]\n",
      "6.0 15.269537925720215\n",
      "0 fold end!\n",
      "NCTF_embeds/factors_4_times_0_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_4_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "NCTF_embeds/factors_4_times_1_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_4_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "NCTF_embeds/factors_4_times_2_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_4_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "NCTF_embeds/factors_4_times_3_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_4_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "NCTF_embeds/factors_4_times_4_fold.pkl\n",
      "pred_score_pkl/NCTF_ddi_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.766  0.95   0.701  0.9474 0.6983 0.9715 0.705 ]]\n",
      "3.0 11.969391822814941\n",
      "25\n",
      "final:\t [[0.7625 0.9498 0.6997 0.9473 0.6953 0.9717 0.7054]]\n",
      "neg=1\n",
      "auc=0.9498\taupr=0.7625\tf1=0.6997\tacc=0.9473\trecall=0.6953\tspe=0.9717\tpre=0.7054\n",
      "\n",
      "37.0 53.13108706474304\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "# 导入模块\n",
    "from drug_oneil_data import GetData\n",
    "from MCTD import Model\n",
    "# from compareNumpyMethod import Model\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "import tensorly as tl\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy.special import expit\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', times=5, folds=5, negs = 10,**kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.parameters = kwargs\n",
    "        self.times = times\n",
    "        self.folds = folds\n",
    "        self.negs= negs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = self.folds\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        # avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        #score = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "            since = time.time()\n",
    "            for k in range(k_folds):\n",
    "                train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                train_tensor[trainpos_index] = 0\n",
    "                # S1 = np.mat(self.drug_drug_data.S1)\n",
    "                # S2 = np.mat(self.drug_drug_data.S2)\n",
    "    \n",
    "                # train_X = tl.tensor(train_tensor)\n",
    "                # S1 = tl.tensor(self.drug_drug_data.S1)\n",
    "                # S2 = tl.tensor(self.drug_drug_data.S2)\n",
    "    \n",
    "                train_X = torch.tensor(train_tensor, dtype=torch.float32)\n",
    "                S1 = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                S2 = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                predict_tensor,M,C,D = self.model()(train_X, S1, S2,\n",
    "                                              r=self.parameters['r'],\n",
    "                                              mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                                              alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                                              lam=self.parameters['lam'],\n",
    "                                              tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                                              # device=self.parameters['device']\n",
    "                                              # net=self.parameters['net']\n",
    "                                              # epoch=self.parameters['epoch'], batch_size=self.parameters['batch_size'],\n",
    "                                              # hids_size=self.parameters['hids_size'],\n",
    "                                              # lr=self.parameters['lr'], weight_decay=self.parameters['weight_decay'],\n",
    "                                              # k=k, label=np.array(self.drug_drug_data.X, copy=True), train_index=train_index,\n",
    "                                              # Y=np.array(self.drug_drug_data.X, copy=True)\n",
    "                                              )\n",
    "    \n",
    "                print(k,'fold end!')\n",
    "                fname='NCTF_embeds/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([M,C,D], f)\n",
    "                \n",
    "                del M,C,D\n",
    "                \n",
    "                #testpos_index 和 posIndex_test是一样的\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = tuple(torch.cat((posIndex_test, negIndex_test), dim=0).numpy().T)\n",
    "                #print(idxs_test)\n",
    "    \n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                \n",
    "                ### 获得预测值\n",
    "                preds = predict_tensor[idxs_test].flatten()\n",
    "                #print(labels_test.cpu().numpy().shape, preds.shape)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_2(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_3(labels_test.cpu().numpy(), preds)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+'NCTF_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([predict_tensor,idxs_test,labels_test.cpu().numpy(),preds], f)\n",
    "\n",
    "\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test[0],\n",
    "                    'm2': idxs_test[1],\n",
    "                    'd': idxs_test[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+'NCTF_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "\n",
    "                metrics=self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics[0])\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j=j+1\n",
    "            \n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t',i+1,':\\t',result)\n",
    "            #avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "            time_elapsed = time.time() - since\n",
    "            print(time_elapsed // 60, time_elapsed % 60)\n",
    "\n",
    "        fname = os.path.join('compareTF', 'NCTF_ddi_'+str(self.negs)+'neg_results_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        print(j)\n",
    "        #print(df)\n",
    "        #print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t',results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t',results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score=np.mat(real_score)\n",
    "        predict_score=np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        #sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "    \n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "    \n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "    \n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "    \n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "    \n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "    \n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "    \n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "    \n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    #neg =10\n",
    "    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "    # drug_drug_data = GetData(miRNA_num=351, disease_num=325,filefolder=folder,signal=11,neg=neg)\n",
    "    since = time.time()\n",
    "    #print(drug_drug_data)\n",
    "    #print(drug_drug_data.shape)\n",
    "    ### Split\n",
    "    times=5\n",
    "    folds=5\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    j=0\n",
    "    r=122\n",
    "    #mu,eta,alpha,beta,lam=0.5,2,0.125,0.125,0.001\n",
    "    mu,eta,alpha,beta,lam=0.5,2,0.125,0.125,0.001\n",
    "    #for neg in [1,2,4,6,8,10]:\n",
    "    for neg in [1]:\n",
    "        signal = 13\n",
    "        miRNA_num = 38\n",
    "        disease_num = 39\n",
    "        folder = '/mnt/sda/liupei/NCTF_new/data/oneil_ddi5cv'\n",
    "        drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "        experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32', times=times, folds=folds,negs=neg,\n",
    "                                 r=r, mu=mu, alpha=alpha, eta=eta, beta=beta, lam=lam, tol=1e-4, max_iter=100)\n",
    "        aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "        df.loc[j] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "        print(f\"neg={neg}\")\n",
    "        print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "        j=j+1\n",
    "\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_1', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_2', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    df.to_csv('NCTF_1negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311e8ff8-8a1d-4924-aea0-fed412091009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38)\n",
      "(38, 38)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(38, 38, 39)\n",
      "4014.0\n",
      "(38, 38, 39)\n",
      "0 fold end!\n",
      "CTF_embeds/factors_0_times_0_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_0_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "CTF_embeds/factors_0_times_1_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_0_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "CTF_embeds/factors_0_times_2_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_0_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "CTF_embeds/factors_0_times_3_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_0_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "CTF_embeds/factors_0_times_4_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.6689 0.928  0.6146 0.9326 0.6071 0.9641 0.6268]]\n",
      "0.0 9.845805883407593\n",
      "0 fold end!\n",
      "CTF_embeds/factors_1_times_0_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_1_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "CTF_embeds/factors_1_times_1_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_1_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "CTF_embeds/factors_1_times_2_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_1_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "CTF_embeds/factors_1_times_3_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_1_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "CTF_embeds/factors_1_times_4_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.6674 0.9238 0.6222 0.9353 0.6031 0.9675 0.6437]]\n",
      "0.0 9.957449674606323\n",
      "0 fold end!\n",
      "CTF_embeds/factors_2_times_0_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_2_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "CTF_embeds/factors_2_times_1_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_2_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "CTF_embeds/factors_2_times_2_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_2_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "CTF_embeds/factors_2_times_3_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_2_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "CTF_embeds/factors_2_times_4_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.6671 0.9271 0.6187 0.9306 0.6383 0.9589 0.6029]]\n",
      "0.0 9.820257902145386\n",
      "0 fold end!\n",
      "CTF_embeds/factors_3_times_0_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_3_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "CTF_embeds/factors_3_times_1_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_3_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "CTF_embeds/factors_3_times_2_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_3_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "CTF_embeds/factors_3_times_3_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_3_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "CTF_embeds/factors_3_times_4_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.6744 0.9284 0.6217 0.9308 0.6432 0.9587 0.6048]]\n",
      "0.0 9.95968770980835\n",
      "0 fold end!\n",
      "CTF_embeds/factors_4_times_0_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_4_times_0_foldscores.pkl\n",
      "1 fold end!\n",
      "CTF_embeds/factors_4_times_1_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_4_times_1_foldscores.pkl\n",
      "2 fold end!\n",
      "CTF_embeds/factors_4_times_2_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_4_times_2_foldscores.pkl\n",
      "3 fold end!\n",
      "CTF_embeds/factors_4_times_3_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_4_times_3_foldscores.pkl\n",
      "4 fold end!\n",
      "CTF_embeds/factors_4_times_4_fold.pkl\n",
      "pred_score_pkl/CTF_ddi_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.6757 0.9291 0.6231 0.9358 0.6011 0.9682 0.648 ]]\n",
      "0.0 10.045060157775879\n",
      "25\n",
      "final:\t [[0.6707 0.9273 0.6201 0.933  0.6186 0.9635 0.6253]]\n",
      "neg=1\n",
      "auc=0.9273\taupr=0.6707\tf1=0.6201\tacc=0.933\trecall=0.6186\tspe=0.9635\tpre=0.6253\n",
      "\n",
      "0.0 50.366504430770874\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "# 导入模块\n",
    "from DataCombine_drug_oneil import GetData\n",
    "#from ourMethod_gpu import Model\n",
    "from compareNumpyMethod import Model\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "import tensorly as tl\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy.special import expit\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', times=5, folds=5, negs = 10,**kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.parameters = kwargs\n",
    "        self.times = times\n",
    "        self.folds = folds\n",
    "        self.negs= negs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = self.folds\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        # avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        #score = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "            since = time.time()\n",
    "            for k in range(k_folds):\n",
    "                train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                train_tensor[trainpos_index] = 0\n",
    "                S1 = np.mat(self.drug_drug_data.S1)\n",
    "                S2 = np.mat(self.drug_drug_data.S2)\n",
    "\n",
    "                predict_tensor,M,C,D = self.model()(train_tensor, S1, S2,\n",
    "                                              r=self.parameters['r'],\n",
    "                                              mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                                              alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                                              lam=self.parameters['lam'],\n",
    "                                              tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                                              # device=self.parameters['device']\n",
    "                                              # net=self.parameters['net']\n",
    "                                              # epoch=self.parameters['epoch'], batch_size=self.parameters['batch_size'],\n",
    "                                              # hids_size=self.parameters['hids_size'],\n",
    "                                              # lr=self.parameters['lr'], weight_decay=self.parameters['weight_decay'],\n",
    "                                              # k=k, label=np.array(self.drug_drug_data.X, copy=True), train_index=train_index,\n",
    "                                              # Y=np.array(self.drug_drug_data.X, copy=True)\n",
    "                                              )\n",
    "    \n",
    "                print(k,'fold end!')\n",
    "                fname='CTF_embeds/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([M,C,D], f)\n",
    "                \n",
    "                del M,C,D\n",
    "                \n",
    "                #testpos_index 和 posIndex_test是一样的\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = tuple(torch.cat((posIndex_test, negIndex_test), dim=0).numpy().T)\n",
    "                #print(idxs_test)\n",
    "    \n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                \n",
    "                ### 获得预测值\n",
    "                preds = predict_tensor[idxs_test].flatten()\n",
    "                #print(labels_test.cpu().numpy().shape, preds.shape)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_2(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_3(labels_test.cpu().numpy(), preds)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+'CTF_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([predict_tensor,idxs_test,labels_test.cpu().numpy(),preds], f)\n",
    "\n",
    "\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test[0],\n",
    "                    'm2': idxs_test[1],\n",
    "                    'd': idxs_test[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+'CTF_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "\n",
    "                metrics=self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics[0])\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j=j+1\n",
    "            \n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t',i+1,':\\t',result)\n",
    "            #avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "            time_elapsed = time.time() - since\n",
    "            print(time_elapsed // 60, time_elapsed % 60)\n",
    "\n",
    "        fname = os.path.join('compareTF', 'CTF_ddi_'+str(self.negs)+'neg_results_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        print(j)\n",
    "        #print(df)\n",
    "        #print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t',results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t',results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score=np.mat(real_score)\n",
    "        predict_score=np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        #sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "    \n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "    \n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "    \n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "    \n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "    \n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "    \n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "    \n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "    \n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    #neg =10\n",
    "    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "    # drug_drug_data = GetData(miRNA_num=351, disease_num=325,filefolder=folder,signal=11,neg=neg)\n",
    "    since = time.time()\n",
    "    #print(drug_drug_data)\n",
    "    #print(drug_drug_data.shape)\n",
    "    ### Split\n",
    "    times=5\n",
    "    folds=5\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    j=0\n",
    "    r=122\n",
    "    mu,eta,alpha,beta,lam=0.5,2,0.125,0.125,0.001\n",
    "    #for neg in [1,2,4,6,8,10]:\n",
    "    for neg in [1]:\n",
    "        signal = 23\n",
    "        miRNA_num = 38\n",
    "        disease_num = 39\n",
    "        folder = '/mnt/sda/liupei/NCTF_new/data/oneil_ddi5cv'\n",
    "        drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "        experiment = Experiments(drug_drug_data, model_name='CTF',  times=times, folds=folds,negs=neg,\n",
    "                             r=r,  mu=0.5, eta=0.2, alpha=0.5, beta=0.5, lam=0.5, tol=1e-6, max_iter=100)\n",
    "        aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "        df.loc[j] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "        print(f\"neg={neg}\")\n",
    "        print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "        j=j+1\n",
    "\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_1', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_2', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    df.to_csv('CTF_1negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183bff51-6c9a-471e-97ec-b1963421f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38)\n",
      "(38, 38)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(38, 38, 39)\n",
      "4014.0\n",
      "(38, 38, 39)\n",
      "pred_score_pkl/TDRC_ddi_0_times_0_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_0_times_1_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_0_times_2_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_0_times_3_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.2894 0.6949 0.3275 0.8725 0.3525 0.9229 0.3078]]\n",
      "1.0 8.613901615142822\n",
      "pred_score_pkl/TDRC_ddi_1_times_0_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_1_times_1_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_1_times_2_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_1_times_3_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.3042 0.7086 0.3493 0.8772 0.3744 0.9259 0.3321]]\n",
      "1.0 8.398711681365967\n",
      "pred_score_pkl/TDRC_ddi_2_times_0_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_2_times_1_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_2_times_2_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_2_times_3_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.2901 0.6942 0.3361 0.8733 0.3625 0.9227 0.316 ]]\n",
      "1.0 8.510181665420532\n",
      "pred_score_pkl/TDRC_ddi_3_times_0_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_3_times_1_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_3_times_2_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_3_times_3_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.2853 0.6919 0.3362 0.8688 0.3767 0.9164 0.305 ]]\n",
      "1.0 8.437694549560547\n",
      "pred_score_pkl/TDRC_ddi_4_times_0_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_4_times_1_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_4_times_2_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_4_times_3_foldscores.pkl\n",
      "pred_score_pkl/TDRC_ddi_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.2892 0.6986 0.3326 0.8608 0.3929 0.9061 0.2919]]\n",
      "1.0 8.652272939682007\n",
      "25\n",
      "final:\t [[0.2917 0.6976 0.3364 0.8705 0.3718 0.9188 0.3106]]\n",
      "neg=1\n",
      "auc=0.6976\taupr=0.2917\tf1=0.3364\tacc=0.8705\trecall=0.3718\tspe=0.9188\tpre=0.3106\n",
      "\n",
      "5.0 43.34939932823181\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "# 导入模块\n",
    "from DataCombine_drug_oneil import GetData\n",
    "#from ourMethod_gpu import Model\n",
    "from compareNumpyMethod import Model\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "import tensorly as tl\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy.special import expit\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', times=5, folds=5, negs = 10,**kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.parameters = kwargs\n",
    "        self.times = times\n",
    "        self.folds = folds\n",
    "        self.negs= negs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = self.folds\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        # avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        #score = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "            since = time.time()\n",
    "            for k in range(k_folds):\n",
    "                train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                train_tensor[trainpos_index] = 0\n",
    "                S1 = np.mat(self.drug_drug_data.S1)\n",
    "                S2 = np.mat(self.drug_drug_data.S2)\n",
    "\n",
    "                predict_tensor = self.model()(train_tensor, S1, S2,\n",
    "                                              r=self.parameters['r'],\n",
    "                                              mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                                              alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                                              lam=self.parameters['lam'],\n",
    "                                              tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                                              # device=self.parameters['device']\n",
    "                                              # net=self.parameters['net']\n",
    "                                              # epoch=self.parameters['epoch'], batch_size=self.parameters['batch_size'],\n",
    "                                              # hids_size=self.parameters['hids_size'],\n",
    "                                              # lr=self.parameters['lr'], weight_decay=self.parameters['weight_decay'],\n",
    "                                              # k=k, label=np.array(self.drug_drug_data.X, copy=True), train_index=train_index,\n",
    "                                              # Y=np.array(self.drug_drug_data.X, copy=True)\n",
    "                                              )\n",
    "    \n",
    "                # print(k,'fold end!')\n",
    "                # fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                # print(fname)\n",
    "                # with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                #     pickle.dump([M,C,D], f)\n",
    "                \n",
    "                # del M,C,D\n",
    "                \n",
    "                #testpos_index 和 posIndex_test是一样的\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = tuple(torch.cat((posIndex_test, negIndex_test), dim=0).numpy().T)\n",
    "                #print(idxs_test)\n",
    "    \n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                \n",
    "                ### 获得预测值\n",
    "                preds = predict_tensor[idxs_test].flatten()\n",
    "                #print(labels_test.cpu().numpy().shape, preds.shape)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_2(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_3(labels_test.cpu().numpy(), preds)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+'TDRC_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([predict_tensor,idxs_test,labels_test.cpu().numpy(),preds], f)\n",
    "\n",
    "\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test[0],\n",
    "                    'm2': idxs_test[1],\n",
    "                    'd': idxs_test[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+'TDRC_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "\n",
    "                metrics=self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics[0])\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j=j+1\n",
    "            \n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t',i+1,':\\t',result)\n",
    "            #avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "            time_elapsed = time.time() - since\n",
    "            print(time_elapsed // 60, time_elapsed % 60)\n",
    "\n",
    "        fname = os.path.join('compareTF', 'TDRC_ddi_'+str(self.negs)+'neg_results_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        print(j)\n",
    "        #print(df)\n",
    "        #print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t',results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t',results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score=np.mat(real_score)\n",
    "        predict_score=np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        #sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "    \n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "    \n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "    \n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "    \n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "    \n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "    \n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "    \n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "    \n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    #neg =10\n",
    "    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "    # drug_drug_data = GetData(miRNA_num=351, disease_num=325,filefolder=folder,signal=11,neg=neg)\n",
    "    since = time.time()\n",
    "    #print(drug_drug_data)\n",
    "    #print(drug_drug_data.shape)\n",
    "    ### Split\n",
    "    times=5\n",
    "    folds=5\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    j=0\n",
    "    r=122\n",
    "    #mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001 ### 旧的NCTF参数组合 再用\n",
    "    #mu,eta,alpha,beta,lam=0.5,0.75,0.5,0.125,0.001 ### 新的NCTF参数组合 不用\n",
    "    #for neg in [1,2,4,6,8,10]:\n",
    "    for neg in [1]:\n",
    "        signal = 23\n",
    "        miRNA_num = 38\n",
    "        disease_num = 39\n",
    "        folder = '/mnt/sda/liupei/NCTF_new/data/oneil_ddi5cv'\n",
    "        drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "        experiment = Experiments(drug_drug_data, model_name='TDRC_mm',  times=times, folds=folds,negs=neg,\n",
    "                                 r=r, mu=0.125, eta=0.25, alpha=2.0, beta=0.125, lam=0.001,  tol=1e-6, max_iter=100)\n",
    "        aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "        df.loc[j] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "        print(f\"neg={neg}\")\n",
    "        print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "        j=j+1\n",
    "\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_1', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_2', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    df.to_csv('TDRC_1negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef642125-fc87-478c-9f16-b2f236d9bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38)\n",
      "(38, 38)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(38, 38, 39)\n",
      "4014.0\n",
      "(38, 38, 39)\n",
      "pred_score_pkl/CP_ddi_0_times_0_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_0_times_1_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_0_times_2_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_0_times_3_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.2337 0.6504 0.279  0.8595 0.3082 0.9129 0.2573]]\n",
      "0.0 1.7558860778808594\n",
      "pred_score_pkl/CP_ddi_1_times_0_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_1_times_1_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_1_times_2_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_1_times_3_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.2404 0.6446 0.2872 0.872  0.2917 0.9281 0.2878]]\n",
      "0.0 1.7693390846252441\n",
      "pred_score_pkl/CP_ddi_2_times_0_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_2_times_1_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_2_times_2_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_2_times_3_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.2211 0.6391 0.2653 0.8586 0.2895 0.9137 0.2462]]\n",
      "0.0 1.7513422966003418\n",
      "pred_score_pkl/CP_ddi_3_times_0_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_3_times_1_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_3_times_2_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_3_times_3_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.2211 0.6406 0.2691 0.8413 0.3298 0.8908 0.2292]]\n",
      "0.0 1.8115663528442383\n",
      "pred_score_pkl/CP_ddi_4_times_0_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_4_times_1_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_4_times_2_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_4_times_3_foldscores.pkl\n",
      "pred_score_pkl/CP_ddi_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.228  0.6429 0.2763 0.8544 0.3142 0.9067 0.2516]]\n",
      "0.0 1.7700855731964111\n",
      "25\n",
      "final:\t [[0.2289 0.6435 0.2754 0.8571 0.3067 0.9104 0.2544]]\n",
      "neg=1\n",
      "auc=0.6435\taupr=0.2289\tf1=0.2754\tacc=0.8571\trecall=0.3067\tspe=0.9104\tpre=0.2544\n",
      "\n",
      "0.0 9.600718259811401\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "# 导入模块\n",
    "from DataCombine_drug_oneil import GetData\n",
    "#from ourMethod_gpu import Model\n",
    "from compareNumpyMethod import Model\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "import tensorly as tl\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy.special import expit\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', times=5, folds=5, negs = 10,**kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.parameters = kwargs\n",
    "        self.times = times\n",
    "        self.folds = folds\n",
    "        self.negs= negs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = self.folds\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        # avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        #score = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "            since = time.time()\n",
    "            for k in range(k_folds):\n",
    "                train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                train_tensor[trainpos_index] = 0\n",
    "                S1 = np.mat(self.drug_drug_data.S1)\n",
    "                S2 = np.mat(self.drug_drug_data.S2)\n",
    "\n",
    "                predict_tensor = self.model()(train_tensor, S1, S2,\n",
    "                                              r=self.parameters['r'],\n",
    "                                              mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                                              alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                                              lam=self.parameters['lam'],\n",
    "                                              tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                                              # device=self.parameters['device']\n",
    "                                              # net=self.parameters['net']\n",
    "                                              # epoch=self.parameters['epoch'], batch_size=self.parameters['batch_size'],\n",
    "                                              # hids_size=self.parameters['hids_size'],\n",
    "                                              # lr=self.parameters['lr'], weight_decay=self.parameters['weight_decay'],\n",
    "                                              # k=k, label=np.array(self.drug_drug_data.X, copy=True), train_index=train_index,\n",
    "                                              # Y=np.array(self.drug_drug_data.X, copy=True)\n",
    "                                              )\n",
    "    \n",
    "                # print(k,'fold end!')\n",
    "                # fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                # print(fname)\n",
    "                # with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                #     pickle.dump([M,C,D], f)\n",
    "                \n",
    "                # del M,C,D\n",
    "                \n",
    "                #testpos_index 和 posIndex_test是一样的\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = tuple(torch.cat((posIndex_test, negIndex_test), dim=0).numpy().T)\n",
    "                #print(idxs_test)\n",
    "    \n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                \n",
    "                ### 获得预测值\n",
    "                preds = predict_tensor[idxs_test].flatten()\n",
    "                #print(labels_test.cpu().numpy().shape, preds.shape)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_2(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_3(labels_test.cpu().numpy(), preds)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+'CP_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([predict_tensor,idxs_test,labels_test.cpu().numpy(),preds], f)\n",
    "\n",
    "\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test[0],\n",
    "                    'm2': idxs_test[1],\n",
    "                    'd': idxs_test[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+'CP_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "\n",
    "                metrics=self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics[0])\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j=j+1\n",
    "            \n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t',i+1,':\\t',result)\n",
    "            #avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "            time_elapsed = time.time() - since\n",
    "            print(time_elapsed // 60, time_elapsed % 60)\n",
    "\n",
    "        fname = os.path.join('compareTF', 'CP_ddi_'+str(self.negs)+'neg_results_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        print(j)\n",
    "        #print(df)\n",
    "        #print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t',results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t',results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score=np.mat(real_score)\n",
    "        predict_score=np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        #sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "    \n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "    \n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "    \n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "    \n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "    \n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "    \n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "    \n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "    \n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    #neg =10\n",
    "    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "    # drug_drug_data = GetData(miRNA_num=351, disease_num=325,filefolder=folder,signal=11,neg=neg)\n",
    "    since = time.time()\n",
    "    #print(drug_drug_data)\n",
    "    #print(drug_drug_data.shape)\n",
    "    ### Split\n",
    "    times=5\n",
    "    folds=5\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    j=0\n",
    "    r=122\n",
    "    #mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001 ### 旧的NCTF参数组合 再用\n",
    "    #mu,eta,alpha,beta,lam=0.5,0.75,0.5,0.125,0.001 ### 新的NCTF参数组合 不用\n",
    "    #for neg in [1,2,4,6,8,10]:\n",
    "    for neg in [1]:\n",
    "        signal = 23\n",
    "        miRNA_num = 38\n",
    "        disease_num = 39\n",
    "        folder = '/mnt/sda/liupei/NCTF_new/data/oneil_ddi5cv'\n",
    "        drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "        experiment = Experiments(drug_drug_data, model_name='CP',  times=times, folds=folds,negs=neg,\n",
    "                         r=r, mu=0.125, eta=0.25, alpha=0.125, beta=0.25, lam=0.001,  tol=1e-6, max_iter=100)\n",
    "        aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "        df.loc[j] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "        print(f\"neg={neg}\")\n",
    "        print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "        j=j+1\n",
    "\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_1', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_2', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    df.to_csv('CP_1negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f15f225-9435-4787-955a-e3d68be04cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38)\n",
      "(38, 38)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(38, 38, 39)\n",
      "4014.0\n",
      "(38, 38, 39)\n",
      "pred_score_pkl/TFAI_ddi_0_times_0_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_0_times_1_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_0_times_2_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_0_times_3_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.4347 0.8222 0.4646 0.8979 0.502  0.9362 0.4329]]\n",
      "0.0 4.7865636348724365\n",
      "pred_score_pkl/TFAI_ddi_1_times_0_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_1_times_1_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_1_times_2_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_1_times_3_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.4465 0.8265 0.474  0.8964 0.5286 0.932  0.4305]]\n",
      "0.0 4.757717609405518\n",
      "pred_score_pkl/TFAI_ddi_2_times_0_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_2_times_1_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_2_times_2_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_2_times_3_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.4318 0.8195 0.4611 0.894  0.5137 0.9308 0.4201]]\n",
      "0.0 4.793220520019531\n",
      "pred_score_pkl/TFAI_ddi_3_times_0_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_3_times_1_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_3_times_2_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_3_times_3_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.4402 0.8259 0.4639 0.8965 0.5065 0.9342 0.4312]]\n",
      "0.0 4.775873899459839\n",
      "pred_score_pkl/TFAI_ddi_4_times_0_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_4_times_1_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_4_times_2_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_4_times_3_foldscores.pkl\n",
      "pred_score_pkl/TFAI_ddi_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.4381 0.8245 0.4579 0.8964 0.4955 0.9352 0.4325]]\n",
      "0.0 4.79123592376709\n",
      "25\n",
      "final:\t [[0.4383 0.8237 0.4643 0.8962 0.5093 0.9337 0.4295]]\n",
      "neg=1\n",
      "auc=0.8237\taupr=0.4383\tf1=0.4643\tacc=0.8962\trecall=0.5093\tspe=0.9337\tpre=0.4295\n",
      "\n",
      "0.0 24.637274742126465\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "# 导入模块\n",
    "from DataCombine_drug_oneil import GetData\n",
    "#from ourMethod_gpu import Model\n",
    "from compareNumpyMethod import Model\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "import tensorly as tl\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy.special import expit\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', times=5, folds=5, negs = 10,**kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.parameters = kwargs\n",
    "        self.times = times\n",
    "        self.folds = folds\n",
    "        self.negs= negs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        fix_seed(2024)\n",
    "        k_folds = self.folds\n",
    "        np.random.seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        # avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        df = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        #score = pd.DataFrame(columns=['j', 'times', 'folds','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "            since = time.time()\n",
    "            for k in range(k_folds):\n",
    "                train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                train_tensor[trainpos_index] = 0\n",
    "                S1 = np.mat(self.drug_drug_data.S1)\n",
    "                S2 = np.mat(self.drug_drug_data.S2)\n",
    "\n",
    "                predict_tensor = self.model()(train_tensor, S1, S2,\n",
    "                                              r=self.parameters['r'],\n",
    "                                              mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                                              alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                                              lam=self.parameters['lam'],\n",
    "                                              tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                                              # device=self.parameters['device']\n",
    "                                              # net=self.parameters['net']\n",
    "                                              # epoch=self.parameters['epoch'], batch_size=self.parameters['batch_size'],\n",
    "                                              # hids_size=self.parameters['hids_size'],\n",
    "                                              # lr=self.parameters['lr'], weight_decay=self.parameters['weight_decay'],\n",
    "                                              # k=k, label=np.array(self.drug_drug_data.X, copy=True), train_index=train_index,\n",
    "                                              # Y=np.array(self.drug_drug_data.X, copy=True)\n",
    "                                              )\n",
    "    \n",
    "                # print(k,'fold end!')\n",
    "                # fname='CTF_embeds/'+str(self.negs)+'n/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                # print(fname)\n",
    "                # with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                #     pickle.dump([M,C,D], f)\n",
    "                \n",
    "                # del M,C,D\n",
    "                \n",
    "                #testpos_index 和 posIndex_test是一样的\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = tuple(torch.cat((posIndex_test, negIndex_test), dim=0).numpy().T)\n",
    "                #print(idxs_test)\n",
    "    \n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                \n",
    "                ### 获得预测值\n",
    "                preds = predict_tensor[idxs_test].flatten()\n",
    "                #print(labels_test.cpu().numpy().shape, preds.shape)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_2(labels_test.cpu().numpy(), preds)\n",
    "                #metrics_tensor = metrics_tensor + self.get_metrics_3(labels_test.cpu().numpy(), preds)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+'TFAI_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([predict_tensor,idxs_test,labels_test.cpu().numpy(),preds], f)\n",
    "\n",
    "\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test[0],\n",
    "                    'm2': idxs_test[1],\n",
    "                    'd': idxs_test[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+'TFAI_ddi_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "\n",
    "                metrics=self.get_metrics_1(labels_test.cpu().numpy(), preds)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics[0])\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, i, k, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j=j+1\n",
    "            \n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t',i+1,':\\t',result)\n",
    "            #avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "            time_elapsed = time.time() - since\n",
    "            print(time_elapsed // 60, time_elapsed % 60)\n",
    "\n",
    "        fname = os.path.join('compareTF', 'TFAI_ddi_'+str(self.negs)+'neg_results_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        print(j)\n",
    "        #print(df)\n",
    "        #print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t',results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t',results_2)\n",
    "        return results_1\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score=np.mat(real_score)\n",
    "        predict_score=np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        #sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "    \n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "    \n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "    \n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "    \n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "    \n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "    \n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "    \n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "    \n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    #neg =10\n",
    "    # folder = '/mnt/sda/liupei/NCTF/newCode/data/hmddv32_neg/'+str(neg)+'n'\n",
    "    # drug_drug_data = GetData(miRNA_num=351, disease_num=325,filefolder=folder,signal=11,neg=neg)\n",
    "    since = time.time()\n",
    "    #print(drug_drug_data)\n",
    "    #print(drug_drug_data.shape)\n",
    "    ### Split\n",
    "    times=5\n",
    "    folds=5\n",
    "    df = pd.DataFrame(columns=['neg','aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity', 'precision'])\n",
    "    j=0\n",
    "    r=122\n",
    "    #mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001 ### 旧的NCTF参数组合 再用\n",
    "    #mu,eta,alpha,beta,lam=0.5,0.75,0.5,0.125,0.001 ### 新的NCTF参数组合 不用\n",
    "    #for neg in [1,2,4,6,8,10]:\n",
    "    for neg in [1]:\n",
    "        signal = 23\n",
    "        miRNA_num = 38\n",
    "        disease_num = 39\n",
    "        folder = '/mnt/sda/liupei/NCTF_new/data/oneil_ddi5cv'\n",
    "        drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "        experiment = Experiments(drug_drug_data, model_name='TFAI_CP_within_mod',  times=times, folds=folds,negs=neg,\n",
    "                                 r=r, mu=0.125, eta=0.25, alpha=2.0, beta=0.125, lam=0.001,  tol=1e-6, max_iter=100)\n",
    "        aupr, auc_value, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "        df.loc[j] = [neg, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "        print(f\"neg={neg}\")\n",
    "        print(f\"auc={auc_value}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "        j=j+1\n",
    "\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_1', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    #experiment = Experiments(drug_drug_data, model_name='NCTF_torch_splitSim_2', r=30, mu=0.5, alpha=0.5, eta=0.2, beta=0.5, lam=0.001, tol=1e-6, max_iter=200)\n",
    "    df.to_csv('TFAI_1negResults.csv',index=False)  # index=False 表示不写入行索引\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01ed86b-2e4b-4ea9-bdab-b0d0b8c3af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 定义文件名\n",
    "# fname = 'score/NCTF_hmddv3.2_1_times_1_foldscores.pkl'\n",
    "\n",
    "# # 读取数据\n",
    "# with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# # 解包数据\n",
    "# predict_tensor, idxs_test, labels_test, preds = data\n",
    "\n",
    "# # # 打印数据\n",
    "# # print(\"Predict Tensor:\", predict_tensor)\n",
    "# # print(\"Test Indices:\", idxs_test)\n",
    "# # print(\"Labels Test:\", labels_test)\n",
    "# # print(\"Predictions:\", preds)\n",
    "\n",
    "# results = pd.DataFrame({\n",
    "#     'time': [1] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "#     'fold': [1] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "#     'm1': idxs_test[0],\n",
    "#     'm2': idxs_test[1],\n",
    "#     'm3': idxs_test[2],\n",
    "#     'true_label': labels_test,\n",
    "#     'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "# })\n",
    "# # 保存为 CSV 文件\n",
    "# csv_file = 'score/NCTF_hmddv3.2_1_times_1_foldscores.csv'\n",
    "# df.to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2b980e-d207-469d-b90b-008196d9a8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6545244e-01,  1.2589991e-01,  1.8950567e-02, ...,\n",
       "        9.8364753e-06,  3.8205550e-04, -2.1582819e-05], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tensor[idxs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3f133e-b943-482d-916a-433c14796060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6545244e-01,  1.2589991e-01,  1.8950567e-02, ...,\n",
       "        9.8364753e-06,  3.8205550e-04, -2.1582819e-05], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tensor[idxs_test].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3a4cca-c514-42d3-910c-43e6c7a6e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'time': [1] * len(idxs_test[0]),  # 假设这是第 1 折\n",
    "    'fold': [1] * len(idxs_test[0]),  # 假设这是第 1 次\n",
    "    'm1': idxs_test[0],\n",
    "    'm2': idxs_test[1],\n",
    "    'm3': idxs_test[2],\n",
    "    'true_label': labels_test,\n",
    "    'pred_score': preds  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36cf4b51-64bd-4107-a706-a747f29cdf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>fold</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>215</td>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>334</td>\n",
       "      <td>195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>121</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>249</td>\n",
       "      <td>110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>146</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5872 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  fold   m1   m2   m3  true_label  pred_score\n",
       "0        1     1  155  154    0         1.0    0.165452\n",
       "1        1     1  155  155    0         1.0    0.125900\n",
       "2        1     1   22   22    1         1.0    0.018951\n",
       "3        1     1   52   53    1         1.0    0.001700\n",
       "4        1     1   81   82    1         1.0    0.373254\n",
       "...    ...   ...  ...  ...  ...         ...         ...\n",
       "5867     1     1  165  215  115         0.0   -0.000266\n",
       "5868     1     1  210  334  195         0.0    0.000410\n",
       "5869     1     1   44  121  282         0.0    0.000010\n",
       "5870     1     1   96  249  110         0.0    0.000382\n",
       "5871     1     1  337  146  256         0.0   -0.000022\n",
       "\n",
       "[5872 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71798aaf-9ced-42be-985d-ccbca2970c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e46e52-c832-402e-86da-e082a1f1d271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
