{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c15ba0b-4415-4916-8fb4-b7fa806a770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liupei/miniconda3/envs/pyg/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 87)\n",
      "(55, 55)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(87, 87, 55)\n",
      "17978.0\n",
      "(87, 87, 55)\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_0_times_0_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████▋                                                                                            | 109/500 [05:25<19:27,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.260475\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_0_times_1_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▊                                                                                  | 152/500 [04:43<10:49,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.260777\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_0_times_2_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████▍                                                                               | 163/500 [03:29<07:13,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.269875\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_0_times_3_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████████▌                                                                                    | 142/500 [03:02<07:39,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.264170\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_0_times_4_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▍                                                                                  | 150/500 [03:12<07:29,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.269717\n",
      "pred_score_pkl/NCTF_ConvKAN_18_0_times_4_foldscores.pkl\n",
      "Times:\t 1 :\t [[0.5514 0.8471 0.5187 0.8858 0.5079 0.9379 0.5304]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_1_times_0_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▏                                                                                  | 149/500 [03:10<07:29,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.261777\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_1_times_1_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▋                                                                                  | 151/500 [03:14<07:28,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.264906\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_1_times_2_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████████████▏                                                                                       | 128/500 [02:44<07:58,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.266951\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_1_times_3_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▋                                                                                    | 143/500 [03:12<08:01,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.264585\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_1_times_4_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████████████                                                                                  | 153/500 [03:24<07:44,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.265035\n",
      "pred_score_pkl/NCTF_ConvKAN_18_1_times_4_foldscores.pkl\n",
      "Times:\t 2 :\t [[0.5525 0.8469 0.5214 0.88   0.5393 0.927  0.5056]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_2_times_0_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████▏                                                                               | 162/500 [03:38<07:35,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.265632\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_2_times_1_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████████████▋                                                                                   | 147/500 [03:18<07:56,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.265560\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_2_times_2_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████▊                                                                                      | 135/500 [03:03<08:14,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.263546\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_2_times_3_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████▋                                                                                        | 126/500 [02:51<08:28,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.264789\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_2_times_4_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████████████▍                                                                                       | 129/500 [02:55<08:25,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.259875\n",
      "pred_score_pkl/NCTF_ConvKAN_18_2_times_4_foldscores.pkl\n",
      "Times:\t 3 :\t [[0.5554 0.8481 0.5238 0.8842 0.5253 0.9337 0.5229]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_3_times_0_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████████████▏                                                                                       | 128/500 [02:50<08:16,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.262326\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_3_times_1_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████▊                                                                                          | 118/500 [02:39<08:35,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.269196\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_3_times_2_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████████████▋                                                                                       | 130/500 [02:55<08:20,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.260640\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_3_times_3_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████████▎                                                                                    | 141/500 [03:10<08:04,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.268074\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_3_times_4_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████████████▋                                                                                   | 147/500 [03:16<07:51,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.266105\n",
      "pred_score_pkl/NCTF_ConvKAN_18_3_times_4_foldscores.pkl\n",
      "Times:\t 4 :\t [[0.55   0.8465 0.5198 0.881  0.5313 0.9293 0.5102]]\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_4_times_0_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████████████▎                                                                                     | 137/500 [03:02<08:04,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, Test Loss: 0.264065\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_0_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_4_times_1_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████▏                                                                               | 162/500 [03:39<07:37,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5, Test Loss: 0.261475\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_1_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_4_times_2_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▏                                                                                  | 149/500 [03:18<07:48,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5, Test Loss: 0.262577\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_2_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_4_times_3_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████████                                                                                     | 140/500 [03:09<08:07,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5, Test Loss: 0.265565\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_3_foldscores.pkl\n",
      "NCTF_ConvKAN_18\n",
      "NCTF_embeds/factors_4_times_4_fold.pkl\n",
      "torch.Size([87, 57]) torch.Size([87, 57]) torch.Size([55, 57])\n",
      "NCTF_ConvKAN_18(\n",
      "  (embeds1): Embedding(87, 57)\n",
      "  (embeds2): Embedding(55, 57)\n",
      "  (conv1): Conv2d(1, 114, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(114, 114, kernel_size=(57, 1), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (act): ReLU()\n",
      "  (output): KANLayers(\n",
      "    (layers): ModuleList(\n",
      "      (0): FastKANLayer(\n",
      "        (layernorm): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
      "        (rbf): RadialBasisFunction()\n",
      "        (spline_linear): SplineLinear(in_features=912, out_features=1, bias=False)\n",
      "        (base_activation): SiLU()\n",
      "        (base_linear): Linear(in_features=114, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▋                                                                                    | 143/500 [03:13<08:03,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5, Test Loss: 0.263125\n",
      "pred_score_pkl/NCTF_ConvKAN_18_4_times_4_foldscores.pkl\n",
      "Times:\t 5 :\t [[0.5556 0.8489 0.5263 0.8837 0.5331 0.9321 0.5206]]\n",
      "final:\t [[0.553  0.8475 0.522  0.8829 0.5274 0.932  0.5179]]\n",
      "\ttimes=5\tmethods=NCTF_ConvKAN_18\tmsi=13\tkernel=[(1, 3), (57, 1)]\tdim=[1]\ta=0.8\n",
      "auc=0.8475\taupr=0.553\tf1=0.522\tacc=0.8829\trecall=0.5274\tspe=0.932\tpre=0.5179\n",
      "\n",
      "82.0 58.579338788986206\n",
      "83.0 1.2650017738342285\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# 添加模块所在的文件夹到 sys.path\n",
    "folder_path = \"/mnt/sda/liupei/NCTF_new/src/\"\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "from DataCombine_drug_nci import GetData\n",
    "from ourMethod_gpu import Model\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_16, NCTF_ConvKAN_16_noeca1, NCTF_ConvKAN_16_noeca2, NCTF_ConvKAN_16_noeca12\n",
    "from newNCTF_NN_3 import NCTF_ConvMLP_16\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_13, NCTF_ConvKAN_1, ConvKAN\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_17, NCTF_ConvKAN_11, ConvKAN_1\n",
    "from newNCTF_NN_3 import Costco\n",
    "from newNCTF_NN_3 import CTF_DDI\n",
    "from newNCTF_NN_3 import DeepSynergy_new, DTF_new\n",
    "from newNCTF_NN_3 import NCTF_ConvMLP_16_noeca12\n",
    "from newNCTF_NN_3 import NCTF_ConvMLP_16_noeca2\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_CBAM\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_18,NCTF_ConvMLP_18,NCTF_KAN_18,NCTF_MLP_18\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_19\n",
    "from newNCTF_NN_3 import NCTF_ConvKAN_20\n",
    "from compareNumpyMethod import Model as numpyModel\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.backends import cudnn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "import math\n",
    "import time\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "# from utils import draw\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "def fix_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "def he_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# def he_init_1(m):\n",
    "#     if isinstance(m, (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d)):\n",
    "#         torch.nn.init.kaiming_normal_(m.weight, mode = 'fan_in')\n",
    "\n",
    "def he_init_1(m):\n",
    "    if isinstance(m, (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d)):\n",
    "        #torch.nn.init.kaiming_normal_(m.weight, mode = 'fan_in')\n",
    "        torch.nn.init.kaiming_normal_(m.weight, a=0, mode = 'fan_in', nonlinearity='relu')\n",
    "        #torch.nn.init.kaiming_normal_(m.weight, a=0.01, mode = 'fan_in', nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "def train_test(model, criterion, lr, epochs, train_loader, val_loader, idxs_test, labels_test,k,k_folds,device):\n",
    "    print(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    min_val, min_test, min_epoch, final_model = 9999, 9999, 0, 0\n",
    "    # 训练模型\n",
    "    # loss_train_list = []\n",
    "    # loss_test_list = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "    #for epoch in range(epochs):\n",
    "        ##训练\n",
    "        model.train()\n",
    "        train_loss, valid_loss = 0, 0\n",
    "        # loss_train_list_batch = []\n",
    "        for inputs in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "            outputs = model(inputs_gpu)\n",
    "            #print(inputs[-1].unsqueeze(1))\n",
    "            loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(inputs)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        # loss_train_list.append(train_loss)\n",
    "\n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        for inputs in val_loader:\n",
    "            with torch.no_grad():\n",
    "                inputs_gpu = [tensor.to(device) for tensor in inputs[:-1]]\n",
    "                outputs = model(inputs_gpu)\n",
    "                loss = criterion(outputs, inputs[-1].unsqueeze(1).to(device))\n",
    "                val_loss += loss.item() * len(inputs)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        # loss_test_list.append(val_loss)\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        #     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if min_val <= val_loss and epoch - min_epoch >= 10:\n",
    "            break\n",
    "\n",
    "        if min_val > val_loss:\n",
    "            min_val = val_loss\n",
    "            min_epoch = epoch\n",
    "            # torch.save(Neural_Model, './best_model.pt')\n",
    "            testModel = model\n",
    "\n",
    "    # draw(loss_train_list, loss_test_list, str(k+1) + '-loss.png')\n",
    "    # print('Finished Training.\\nK-fold, Epoch, min val_loss ({},{},{})'.format(k, min_epoch, min_val))\n",
    "    # 测试模型\n",
    "    testModel.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs_gpu = idxs_test.T.to(device)\n",
    "        outputs = testModel(inputs_gpu)\n",
    "        loss = criterion(outputs, labels_test.unsqueeze(1).to(device))\n",
    "        print(f\"Fold {k + 1}/{k_folds}, Test Loss: {loss:.6f}\")\n",
    "    return outputs,testModel\n",
    "\n",
    "class Experiments(object):\n",
    "\n",
    "    def __init__(self, drug_drug_data, model_name='NCTF', msi=10, times=10,folds=5,a=0.5,negs=1,\n",
    "                 lr=0.001, epoch=150, batch_size=2048, nc=57,\n",
    "                 kernel_size=[(1, 3), (57, 1)], dims=[1],\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.drug_drug_data = drug_drug_data\n",
    "        self.model = Model(model_name)\n",
    "        self.numpyModel = numpyModel(model_name)\n",
    "        self.msi = msi\n",
    "        self.times = times\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.channel = nc\n",
    "        self.shape = drug_drug_data.X.shape\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dims = dims\n",
    "        self.folds = folds\n",
    "        self.a = a\n",
    "        self.negs = negs\n",
    "        self.parameters = kwargs\n",
    "\n",
    "    def CV_triplet(self):\n",
    "        k_folds = self.folds\n",
    "        fix_seed(2024)\n",
    "        metrics_tensor_all = np.zeros((1, 7))\n",
    "        avgmetrics_tensor_10 = np.zeros((1, 7))\n",
    "        j = 0\n",
    "        kname = ['kernel1', 'kernel2','kernel3']\n",
    "        dname = ['dims1', 'dims2', 'dima3']\n",
    "        kernel_sizeList = [[(1, len(self.shape)), (r, 1)], [(r, 1), (1, len(self.shape))]]  # our\n",
    "        #kernel_sizeList = [[(1, len(self.shape)), (r, 1)], [(r, 1), (1, len(self.shape))], [(1, 1),(1, len(self.shape)), (r, 1)]]\n",
    "        dimsList = [[1], [self.channel, 1], [self.channel, self.channel, 1]]  # pre层\n",
    "        s1=kname[kernel_sizeList.index(self.kernel_size)]\n",
    "        s2=dname[dimsList.index(self.dims)]\n",
    "        df = pd.DataFrame(columns=['j', 'methods', 'times', 'folds', 'kernel', 'dims', 'aupr', 'auc', 'f1_score', 'accuracy',\n",
    "                     'recall', 'specificity',\n",
    "                     'precision'])\n",
    "        for i in range(self.times):\n",
    "            index_matrix = self.drug_drug_data.posidx[i].numpy().T\n",
    "            poscv = self.drug_drug_data.poscv[i].numpy()\n",
    "            neg_matrix = self.drug_drug_data.negidx[i].numpy().T\n",
    "            negcv = self.drug_drug_data.negcv[i].numpy()\n",
    "            metrics_tensor = np.zeros((1, 7))\n",
    "\n",
    "            for k in range(k_folds):\n",
    "                ### Train data\n",
    "                # posIndex_train = torch.tensor(torch.nonzero(train_X == 1), dtype=torch.int)\n",
    "                posIndex_train = torch.tensor(index_matrix[:, np.where(poscv != k)[0]]).T\n",
    "                negIndex_train = torch.tensor(neg_matrix[:, np.where(negcv != k)[0]]).T\n",
    "                idxs_train = torch.cat((posIndex_train, negIndex_train), dim=0)\n",
    "                # print(idxs_train)\n",
    "                # print(idxs_train.shape)\n",
    "                poslabel_train = torch.ones(posIndex_train.shape[0])\n",
    "                neglabel_train = torch.zeros(negIndex_train.shape[0])\n",
    "                labels_train = torch.cat((poslabel_train, neglabel_train), dim=0)\n",
    "                # print(labels_train.shape)\n",
    "\n",
    "                ### 划分验证集\n",
    "                idxs = idxs_train.numpy().astype(int)\n",
    "                vals = labels_train.numpy().astype(float)\n",
    "                # print(idxs,vals)\n",
    "                # print(idxs.shape, vals.shape)\n",
    "                idxs_train1, idxs_val, labels_train1, labels_val = train_test_split(idxs, vals, test_size=0.1)\n",
    "                # idxs_train, idxs_val, labels_train, labels_val = train_test_split(idxs_train, labels_train, test_size=0.1)\n",
    "\n",
    "                ### Test data\n",
    "                posIndex_test = torch.tensor(index_matrix[:, np.where(poscv == k)[0]], dtype=torch.int).T\n",
    "                negIndex_test = torch.tensor(neg_matrix[:, np.where(negcv == k)[0]], dtype=torch.int).T\n",
    "                idxs_test = torch.cat((posIndex_test, negIndex_test), dim=0)\n",
    "                # print(idxs_test)\n",
    "                # print(idxs_test.shape)\n",
    "                poslabel_test = torch.ones(posIndex_test.shape[0])\n",
    "                neglabel_test = torch.zeros(negIndex_test.shape[0])\n",
    "                labels_test = torch.cat((poslabel_test, neglabel_test), dim=0)\n",
    "                # print(labels_test.shape)\n",
    "\n",
    "                # 模型超参数\n",
    "                shape = self.drug_drug_data.X.shape\n",
    "                rank = self.parameters['r']\n",
    "                nc = self.channel\n",
    "                kernel_size = self.kernel_size  # 0-our 1-costco原始设置\n",
    "                # kernel_size2= [(rank,1),(1,len(shape))] #costco原始设置\n",
    "                dims = self.dims\n",
    "                lr = self.lr\n",
    "                epochs = self.epoch\n",
    "                batch_size = self.batch_size\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                # 创建数据加载器\n",
    "                idxs_train1 = torch.LongTensor(idxs_train1)\n",
    "                idxs_val = torch.LongTensor(idxs_val)\n",
    "                # idxs_test = torch.LongTensor(idxs_test)\n",
    "                labels_train1 = torch.FloatTensor(labels_train1)\n",
    "                labels_val = torch.FloatTensor(labels_val)\n",
    "                # labels_test = torch.FloatTensor(labels_test)\n",
    "\n",
    "                train_dataset = TensorDataset(*[idxs_train1[:, i] for i in range(len(shape))], labels_train1)\n",
    "                val_dataset = TensorDataset(*[idxs_val[:, i] for i in range(len(shape))], labels_val)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                del train_dataset, val_dataset\n",
    "\n",
    "                msi = [1, 2,\n",
    "                       3,4,5,\n",
    "                       6,\n",
    "                       7,8,9,10,\n",
    "                       11,12,\n",
    "                          13,14,15,16,17,18]\n",
    "                mnameList = ['NCTF_ConvKAN_16','NCTF_ConvMLP_16',\n",
    "                             'NCTF_ConvKAN_16_noeca1','NCTF_ConvKAN_16_noeca2','NCTF_ConvKAN_16_noeca12',\n",
    "                             'NCTF_ConvKAN_17',\n",
    "                             'NCTF_ConvMLP_16_noeca12','NCTF_ConvKAN_13','NCTF_ConvKAN_1','ConvKAN',\n",
    "                             'NCTF_ConvMLP_16_noeca2','NCTF_ConvKAN_CBAM',\n",
    "                            'NCTF_ConvKAN_18','NCTF_ConvKAN_19','NCTF_ConvKAN_20','NCTF_ConvMLP_18','NCTF_KAN_18','NCTF_MLP_18']\n",
    "                mname = mnameList[msi.index(self.msi)]\n",
    "                print(mname)\n",
    "\n",
    "                ##### 获取NCTF学习所得的因子矩阵 M, C, D #####\n",
    "                ### end to end 学习M C D\n",
    "                # train_tensor = np.array(self.drug_drug_data.X, copy=True)\n",
    "                # trainpos_index = tuple(index_matrix[:, np.where(poscv == k)[0]])\n",
    "                # train_tensor[trainpos_index] = 0\n",
    "                # train_X = torch.tensor(train_tensor, dtype=torch.float32)\n",
    "                # S1 = torch.tensor(self.drug_drug_data.S1, dtype=torch.float32)\n",
    "                # S2 = torch.tensor(self.drug_drug_data.S2, dtype=torch.float32)\n",
    "                # _, M, C, D = self.model()(train_X, S1, S2,\n",
    "                #                           r=self.parameters['r'],\n",
    "                #                           mu=self.parameters['mu'], eta=self.parameters['eta'],\n",
    "                #                           alpha=self.parameters['alpha'], beta=self.parameters['beta'],\n",
    "                #                           lam=self.parameters['lam'],\n",
    "                #                           tol=self.parameters['tol'], max_iter=self.parameters['max_iter']\n",
    "                #                           )\n",
    "                # print('NCTF')\n",
    "\n",
    "                ### 直接导入提前学习好的因子矩阵 \n",
    "                fname='NCTF_embeds/factors_'+str(i)+'_times_'+str(k)+'_fold.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "                    M, C, D = pickle.load(f)\n",
    "                M = M.to(device)\n",
    "                C = C.to(device)\n",
    "                D = D.to(device)\n",
    "                \n",
    "                print(M.shape, C.shape, D.shape)\n",
    "                \n",
    "                ### 构建深度非线性模型 ### 定义损失函数 和 优化器\n",
    "                if self.msi == 1:\n",
    "                    Neural_Model = NCTF_ConvKAN_16(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 2:\n",
    "                    Neural_Model = NCTF_ConvMLP_16(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 3:\n",
    "                    Neural_Model = NCTF_ConvKAN_16_noeca1(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "                elif self.msi == 4:\n",
    "                    Neural_Model = NCTF_ConvKAN_16_noeca2(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "                elif self.msi == 5:\n",
    "                    Neural_Model = NCTF_ConvKAN_16_noeca12(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "                    \n",
    "                elif self.msi == 6:\n",
    "                    Neural_Model = NCTF_ConvKAN_17(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 7:\n",
    "                    Neural_Model = NCTF_ConvMLP_16_noeca12(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 8:\n",
    "                    Neural_Model = NCTF_ConvKAN_13(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 9:\n",
    "                    Neural_Model = NCTF_ConvKAN_1(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                  dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 10:\n",
    "                    Neural_Model = ConvKAN(shape, rank, nc, device,\n",
    "                                           kernel_size=kernel_size, dims=dims,\n",
    "                                           act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 11:\n",
    "                    Neural_Model = NCTF_ConvMLP_16_noeca2(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 12:\n",
    "                    Neural_Model = NCTF_ConvKAN_CBAM(shape, rank, M, C, D, device, kernel_size,nc=[nc,nc],\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 13:\n",
    "                    Neural_Model = NCTF_ConvKAN_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                elif self.msi == 14:\n",
    "                    sim=[S1.to(device),S1.to(device),S2.to(device)]\n",
    "                    Neural_Model = NCTF_ConvKAN_19(shape, rank, M, C, D, device, sim, kernel_size,nc=[nc,nc],\n",
    "                                                  dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 15:\n",
    "                    sim=[S1.to(device),S1.to(device),S2.to(device)]\n",
    "                    Neural_Model = NCTF_ConvKAN_20(shape, rank, M, C, D, device, sim, kernel_size,nc=[nc,nc],\n",
    "                                                  dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0).to(device)\n",
    "\n",
    "                elif self.msi == 16:\n",
    "                    Neural_Model = NCTF_ConvMLP_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                elif self.msi == 17:\n",
    "                    Neural_Model = NCTF_KAN_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.SiLU, dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                elif self.msi == 18:\n",
    "                    Neural_Model = NCTF_MLP_18(shape, rank, nc, M, C, D, device, kernel_size,\n",
    "                                                   dims=dims, act_func=nn.ReLU(), dropout=0.0, input_dropout=0.0,alpha = self.a).to(device)\n",
    "\n",
    "                # print(Neural_Model)\n",
    "                #criterion = nn.MSELoss()\n",
    "                Neural_Model.apply(he_init_1)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "                # optimizer = optim.Adam(Neural_Model.parameters(), lr=lr)\n",
    "                outputs,testModel = train_test(Neural_Model, criterion, lr, epochs, train_loader, val_loader, idxs_test, labels_test, k, k_folds, device)\n",
    "\n",
    "                ### 存储每折每次的预测和真实值\n",
    "                # fname='newscore/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores_mse.pkl'\n",
    "                # print(fname)\n",
    "                # with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                #     pickle.dump([labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                ## 存储每折每次的预测和真实值\n",
    "                fname='pred_score_pkl/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.pkl'\n",
    "                print(fname)\n",
    "                with open(fname, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "                    pickle.dump([testModel,idxs_test,labels_test.cpu().numpy(),outputs.T[0].cpu().numpy()], f)\n",
    "\n",
    "                # print(idxs_test.T)\n",
    "                # print(idxs_test.T[0],len(idxs_test.T[0]))\n",
    "                results = pd.DataFrame({\n",
    "                    'time': [i] * len(idxs_test.T[0]),  # 假设这是第 1 折\n",
    "                    'fold': [k] * len(idxs_test.T[0]),  # 假设这是第 1 次\n",
    "                    'm1': idxs_test.T[0],\n",
    "                    'm2': idxs_test.T[1],\n",
    "                    'd': idxs_test.T[2],\n",
    "                    'true_label': labels_test.cpu().numpy(),\n",
    "                    'pred_score': outputs.T[0].cpu().numpy()  # 假设 preds 是一个二维数组，取第二列作为预测概率\n",
    "                })\n",
    "                # 保存为 CSV 文件\n",
    "                fname='pred_score_csv/'+mname+'_'+str(i)+'_times_'+str(k)+'_foldscores.csv'\n",
    "                results.to_csv(fname, index=False)\n",
    "                \n",
    "                ### 计算评价指标\n",
    "                metrics = self.get_metrics_1(labels_test.cpu().numpy(), outputs.T[0].cpu().numpy())\n",
    "                # print(metrics)\n",
    "                metrics_tensor = metrics_tensor + metrics\n",
    "                metrics_tensor_all = metrics_tensor_all + metrics\n",
    "                # print(metrics)\n",
    "                aupr, auc_value, f1_score, accuracy, recall, specificity, precision = metrics\n",
    "                df.loc[j] = [j, mname, i, k, kernel_size, dims, aupr, auc_value, f1_score, accuracy, recall, specificity, precision]\n",
    "                j = j + 1\n",
    "\n",
    "            result = np.around(metrics_tensor / k_folds, decimals=4)\n",
    "            print('Times:\\t', i + 1, ':\\t', result)\n",
    "            avgmetrics_tensor_10 = avgmetrics_tensor_10 + result\n",
    "\n",
    "        #print(self.a,str(self.a))\n",
    "        sname = s1 + '_' + s2 + '_' + str(self.a)\n",
    "        # fname = os.path.join('newablation/new3', mname + '_' + sname + '_hmddv32_5times5CV_1neg_results_bceheinit.csv')\n",
    "        # print(fname)\n",
    "        # df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        fname = os.path.join('compareTF', mname + '_' + sname + '_ddi_'+str(self.negs)+'neg_results_bceheinit_fixed_new.csv')\n",
    "        df.to_csv(fname, index=False)  # index=False 表示不写入行索引\n",
    "        # print(j)\n",
    "        # print(df)\n",
    "        # print(metrics_tensor_all)\n",
    "        results_1 = np.around(metrics_tensor_all / j, decimals=4)\n",
    "        print('final:\\t', results_1)\n",
    "        # results_2 = np.around(avgmetrics_tensor_10 / self.times, decimals=4)\n",
    "        # print('final:\\t', results_2)\n",
    "        return results_1\n",
    "\n",
    "\n",
    "    def get_metrics_1(self, real_score, predict_score):\n",
    "        real_score = np.mat(real_score)\n",
    "        predict_score = np.mat(predict_score)\n",
    "        # print(real_score)\n",
    "        # print(real_score.shape)\n",
    "        # print(predict_score)\n",
    "        # print(predict_score.shape)\n",
    "        np.random.seed(2024)\n",
    "        sorted_predict_score = np.array(sorted(list(set(np.array(predict_score).flatten()))))\n",
    "        # sorted_predict_score = np.array(sorted(list(set(predict_score))))\n",
    "        # print(sorted_predict_score)\n",
    "        # print(sorted_predict_score.shape)\n",
    "        # print(np.array(real_score).flatten())\n",
    "        sorted_predict_score_num = len(sorted_predict_score)\n",
    "        thresholds = sorted_predict_score[\n",
    "            (np.array([sorted_predict_score_num]) * np.arange(1, 1000) / np.array([1000])).astype(int)]\n",
    "        thresholds = np.mat(thresholds)\n",
    "        thresholds_num = thresholds.shape[1]\n",
    "\n",
    "        predict_score_matrix = np.tile(predict_score, (thresholds_num, 1))\n",
    "        negative_index = np.where(predict_score_matrix < thresholds.T)\n",
    "        positive_index = np.where(predict_score_matrix >= thresholds.T)\n",
    "        predict_score_matrix[negative_index] = 0\n",
    "        predict_score_matrix[positive_index] = 1\n",
    "\n",
    "        # print(real_score.T)\n",
    "        # print(real_score.T.shape)\n",
    "        # print(np.mat(real_score).T)\n",
    "        # print(np.mat(real_score).T.shape)\n",
    "        # print(predict_score_matrix.shape)\n",
    "        TP = predict_score_matrix * real_score.T\n",
    "        FP = predict_score_matrix.sum(axis=1) - TP\n",
    "        FN = real_score.sum() - TP\n",
    "        TN = len(real_score.T) - TP - FP - FN\n",
    "\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr = TP / (TP + FN)\n",
    "        ROC_dot_matrix = np.mat(sorted(np.column_stack((fpr, tpr)).tolist())).T\n",
    "        # print(ROC_dot_matrix)\n",
    "        ROC_dot_matrix.T[0] = [0, 0]\n",
    "        ROC_dot_matrix = np.c_[ROC_dot_matrix, [1, 1]]\n",
    "        x_ROC = ROC_dot_matrix[0].T\n",
    "        y_ROC = ROC_dot_matrix[1].T\n",
    "\n",
    "        auc = 0.5 * (x_ROC[1:] - x_ROC[:-1]).T * (y_ROC[:-1] + y_ROC[1:])\n",
    "\n",
    "        recall_list = tpr\n",
    "        precision_list = TP / (TP + FP)\n",
    "        PR_dot_matrix = np.mat(sorted(np.column_stack((recall_list, -precision_list)).tolist())).T\n",
    "        PR_dot_matrix[1, :] = -PR_dot_matrix[1, :]\n",
    "        PR_dot_matrix.T[0] = [0, 1]\n",
    "        PR_dot_matrix = np.c_[PR_dot_matrix, [1, 0]]\n",
    "        x_PR = PR_dot_matrix[0].T\n",
    "        y_PR = PR_dot_matrix[1].T\n",
    "        aupr = 0.5 * (x_PR[1:] - x_PR[:-1]).T * (y_PR[:-1] + y_PR[1:])\n",
    "\n",
    "        f1_score_list = 2 * TP / (len(real_score.T) + TP - TN)\n",
    "        accuracy_list = (TP + TN) / len(real_score.T)\n",
    "        specificity_list = TN / (TN + FP)\n",
    "\n",
    "        max_index = np.argmax(f1_score_list)\n",
    "        f1_score = f1_score_list[max_index, 0]\n",
    "        accuracy = accuracy_list[max_index, 0]\n",
    "        specificity = specificity_list[max_index, 0]\n",
    "        recall = recall_list[max_index, 0]\n",
    "        precision = precision_list[max_index, 0]\n",
    "\n",
    "        return aupr[0, 0], auc[0, 0], f1_score, accuracy, recall, specificity, precision\n",
    "        \n",
    "    def get_metrics_2(self, real_score, predict_score):\n",
    "        np.random.seed(2024)\n",
    "        # trues, preds =  np.array(real_score).flatten(),np.array(predict_score).flatten()\n",
    "        print(predict_score)\n",
    "        trues, preds = real_score, expit(predict_score)\n",
    "        print(preds)\n",
    "        # print(preds, trues)\n",
    "        fpr1, tpr1, thresholds1 = roc_curve(trues, preds, pos_label=1)\n",
    "        auc_value = auc(fpr1, tpr1)\n",
    "        # print(thresholds1)\n",
    "        # auc_value = roc_auc_score(trues, preds)\n",
    "        precision, recall, thresholds2 = precision_recall_curve(trues, preds, pos_label=1)\n",
    "        precision = precision + np.finfo(float).tiny  # 添加极小值防止出现0\n",
    "        recall = recall + np.finfo(float).tiny  # 添加极小值防止出现0\n",
    "        # print(thresholds2)\n",
    "\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "        best_f1_index = f1_scores.argmax()\n",
    "        best_f1 = f1_scores[best_f1_index]\n",
    "        best_threshold = thresholds2[best_f1_index]\n",
    "        print('Best F1 Score:', best_f1)\n",
    "        print('Best Threshold:', best_threshold)\n",
    "        best_recall = recall[best_f1_index]\n",
    "        best_precision = precision[best_f1_index]\n",
    "        print(best_recall, best_precision)\n",
    "        f1_scores = 2 * (best_precision * best_recall) / (best_precision + best_recall)\n",
    "        print(f1_scores)\n",
    "        print(best_recall, best_precision, f1_scores)\n",
    "\n",
    "        # best_threshold = np.median(thresholds1) # 中位数\n",
    "\n",
    "        aupr = average_precision_score(trues, preds, pos_label=1)\n",
    "        preds1 = preds\n",
    "        preds1[preds > best_threshold] = 1\n",
    "        preds1[preds <= best_threshold] = 0\n",
    "\n",
    "        labels = [1]\n",
    "        TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        for label in labels:\n",
    "            preds_tmp = np.array([1 if pred == label else 0 for pred in preds1])\n",
    "            trues_tmp = np.array([1 if true == label else 0 for true in trues])\n",
    "            # print(preds_tmp, trues_tmp)\n",
    "            # print()\n",
    "            # TP预测为1真实为1\n",
    "            # TN预测为0真实为0\n",
    "            # FN预测为0真实为1\n",
    "            # FP预测为1真实为0\n",
    "            TP += ((preds_tmp == 1) & (trues_tmp == 1)).sum()\n",
    "            TN += ((preds_tmp == 0) & (trues_tmp == 0)).sum()\n",
    "            FN += ((preds_tmp == 0) & (trues_tmp == 1)).sum()\n",
    "            FP += ((preds_tmp == 1) & (trues_tmp == 0)).sum()\n",
    "        print(TP, FP, FN, TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        specificity = TN / (TN + FP)\n",
    "        npre = TN / (TN + FN)\n",
    "        fpr = FP / (TN + FP)\n",
    "        fnr = FN / (TP + FN)\n",
    "        print(recall, precision, f1_score)\n",
    "\n",
    "        return aupr, auc_value, f1_score, accuracy, recall, specificity, precision\n",
    "\n",
    "    def get_metrics_3(self, real_score, predict_score):\n",
    "        # fpr1, tpr1, thresholds = roc_curve(trues, preds, pos_label=1)\n",
    "        # auc_value = auc(fpr1, tpr1)\n",
    "        print(predict_score)\n",
    "        trues, preds = real_score, expit(predict_score)\n",
    "        print(preds)\n",
    "        auc_value = roc_auc_score(trues, preds)\n",
    "        # precision1, recall1, _ = precision_recall_curve(trues, preds, pos_label=1)\n",
    "        aupr = average_precision_score(trues, preds, pos_label=1)\n",
    "        preds1 = preds\n",
    "        # preds1[preds1 > 0.5] = 1\n",
    "        # preds1[preds1 <= 0.5] = 0\n",
    "        preds1[preds1 > np.median(preds)] = 1\n",
    "        preds1[preds1 <= np.median(preds)] = 0\n",
    "\n",
    "        labels = [1]\n",
    "        TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        for label in labels:\n",
    "            preds_tmp = np.array([1 if pred == label else 0 for pred in preds1])\n",
    "            trues_tmp = np.array([1 if true == label else 0 for true in trues])\n",
    "            print(preds_tmp, trues_tmp)\n",
    "            # print()\n",
    "            # TP预测为1真实为1\n",
    "            # TN预测为0真实为0\n",
    "            # FN预测为0真实为1\n",
    "            # FP预测为1真实为0\n",
    "            TP += ((preds_tmp == 1) & (trues_tmp == 1)).sum()\n",
    "            TN += ((preds_tmp == 0) & (trues_tmp == 0)).sum()\n",
    "            FN += ((preds_tmp == 0) & (trues_tmp == 1)).sum()\n",
    "            FP += ((preds_tmp == 1) & (trues_tmp == 0)).sum()\n",
    "        print(TP, FP, FN, TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        specificity = TN / (TN + FP)\n",
    "        npre = TN / (TN + FN)\n",
    "        fpr = FP / (TN + FP)\n",
    "        fnr = FN / (TP + FN)\n",
    "\n",
    "        return aupr, auc_value, f1, accuracy, recall, specificity, precision\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed(2024)\n",
    "    ### 导入数据\n",
    "    since = time.time()\n",
    "    ###循环次数\n",
    "    times = 5\n",
    "    ### 导入数据\n",
    "    #folder = '/mnt/sda/liupei/NCTF/newCode/data/newmmd_10times_5cv'\n",
    "    signal = 13\n",
    "    miRNA_num = 87\n",
    "    disease_num = 55\n",
    "    folder = '/mnt/sda/liupei/NCTF_new/data/NCI_ddi5cv'\n",
    "    drug_drug_data = GetData(miRNA_num=miRNA_num, disease_num=disease_num, filefolder=folder, signal=signal)\n",
    "    ## 设置参数\n",
    "    # lr = 0.0001  ## 设置均不同\n",
    "    # batch_size = 1024 #1024\n",
    "    epoch = 500\n",
    "    shape = drug_drug_data.X.shape\n",
    "    ### 搜索最优配置\n",
    "    msiList = [1, 2,\n",
    "               3,4,5,\n",
    "               6,\n",
    "               7,8,9,10,\n",
    "               11,\n",
    "              12,13,14,15,16,17,18]\n",
    "    mnameList = ['NCTF_ConvKAN_16','NCTF_ConvMLP_16',\n",
    "                 'NCTF_ConvKAN_16_noeca1','NCTF_ConvKAN_16_noeca2','NCTF_ConvKAN_16_noeca12',\n",
    "                 'NCTF_ConvKAN_17',\n",
    "                 'NCTF_ConvMLP_16_noeca12','NCTF_ConvKAN_13','NCTF_ConvKAN_1','ConvKAN',\n",
    "                 'NCTF_ConvMLP_16_noeca2',\n",
    "                'NCTF_ConvKAN_CBAM','NCTF_ConvKAN_18','NCTF_ConvKAN_19','NCTF_ConvKAN_20','NCTF_ConvMLP_18','NCTF_KAN_18','NCTF_MLP_18']\n",
    "    df = pd.DataFrame(columns=['methods', 'a','nc','lr','batch_size','epoch','times', 'kernel', 'dim', 'aupr', 'auc', 'f1_score', 'accuracy', 'recall', 'specificity','precision'])\n",
    "    i = 0\n",
    "    #kernel_size = kernel_sizeList[0]\n",
    "    #dims = dimsList[0]\n",
    "    folds = 5\n",
    "    #mu,eta,alpha,beta,lam=0.75,0.125,0.25,0.25,0.001\n",
    "    #mu,eta,alpha,beta,lam=0.25,2,0.125,0.125,0.001\n",
    "    mu,eta,alpha,beta,lam=0.5,2,0.125,0.125,0.001\n",
    "    r = 57\n",
    "    lrList = [0.001, 0.0001,0.00001]#3\n",
    "    #epochList = [100, 300, 500]\n",
    "    batch_sizeList = [256, 512, 1024]#4\n",
    "    ncList = [int(0.5*r), r, int(2*r)]  # 3\n",
    "    #nc = int(2*r)\n",
    "    kernel_sizeList = [[(1, len(shape)), (r, 1)], [(r, 1), (1, len(shape))]]  # our\n",
    "    #dimsList = [[1], [nc, 1], [nc, nc, 1]]  # pre层\n",
    "    #alist = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "    for msi in [13]:\n",
    "        mname = mnameList[msiList.index(msi)]\n",
    "        print(mname)\n",
    "        dims = [1]# one-layer\n",
    "        kernel_size = kernel_sizeList[0]\n",
    "        if msi in [13]:\n",
    "            alist = [0.8]\n",
    "        else:\n",
    "            alist = [0.8]\n",
    "        for lr in [0.00001]:#3 0.00001\n",
    "            #for nc in ncList:\n",
    "            for batch_size in [512]:#4 512\n",
    "                for nc in [int(2*r)]:#3 2r\n",
    "                    for a in alist:#11\n",
    "                        since1 = time.time()\n",
    "                        experiment = Experiments(drug_drug_data, model_name='NCTF_torch_gpu_float32', msi=msi, times=times, folds=folds,a=a,\n",
    "                                                 lr=lr, epoch=epoch, batch_size=batch_size, nc=nc,\n",
    "                                                 kernel_size=kernel_size, dims=dims,\n",
    "                                                 r=r, mu=mu, eta=eta, alpha=alpha, beta=beta,lam=lam, tol = 1e-4, max_iter = 100)\n",
    "                \n",
    "                        aupr, auc, f1_score, accuracy, recall, specificity, precision = experiment.CV_triplet()[0]\n",
    "                        df.loc[i] = [mname, a, nc,lr,batch_size,epoch,times, kernel_size, dims, aupr, auc, f1_score, accuracy, recall, specificity,\n",
    "                                     precision]\n",
    "                        print(f\"\\ttimes={times}\\tmethods={mname}\\tmsi={msi}\\tkernel={kernel_size}\\tdim={dims}\\ta={a}\")\n",
    "                        print(f\"auc={auc}\\taupr={aupr}\\tf1={f1_score}\\tacc={accuracy}\\trecall={recall}\\tspe={specificity}\\tpre={precision}\\n\")\n",
    "                        i = i + 1\n",
    "                        time_elapsed1 = time.time() - since1\n",
    "                        print(time_elapsed1 // 60, time_elapsed1 % 60)\n",
    "\n",
    "    df.to_csv('NCTFConvKAN18_negResults_fixed_new.csv',index=False)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(time_elapsed // 60, time_elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f5582-b724-4e17-8475-70d4dbd2180b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
